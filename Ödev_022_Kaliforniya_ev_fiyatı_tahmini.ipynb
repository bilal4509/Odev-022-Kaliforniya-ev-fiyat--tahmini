{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='11.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mbNqdBK5mZXA"
   },
   "outputs": [],
   "source": [
    "#pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HDj6qYrNnGoE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "t3VD3ANqnTrE"
   },
   "outputs": [],
   "source": [
    "#Regression AutoMl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "D0JY6Dl4nZQb"
   },
   "outputs": [],
   "source": [
    "from pycaret.regression import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "6m088K49nh1T"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "-UOHxRRDnrgh",
    "outputId": "82f129d2-a902-4d96-a528-e234823fce21"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5d260c84-5989-451c-95d3-461c2b2074b2\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.3859</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.827160</td>\n",
       "      <td>1.112100</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>2.486989</td>\n",
       "      <td>34.60</td>\n",
       "      <td>-120.12</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.7188</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.013373</td>\n",
       "      <td>1.054217</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>3.813084</td>\n",
       "      <td>38.69</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.7750</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.535604</td>\n",
       "      <td>1.103175</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>2.464602</td>\n",
       "      <td>34.71</td>\n",
       "      <td>-120.45</td>\n",
       "      <td>1.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.4138</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.350203</td>\n",
       "      <td>0.965432</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>2.089286</td>\n",
       "      <td>32.66</td>\n",
       "      <td>-117.09</td>\n",
       "      <td>1.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.7500</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.284404</td>\n",
       "      <td>1.069246</td>\n",
       "      <td>1793.0</td>\n",
       "      <td>1.604790</td>\n",
       "      <td>37.80</td>\n",
       "      <td>-122.41</td>\n",
       "      <td>4.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d260c84-5989-451c-95d3-461c2b2074b2')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-5d260c84-5989-451c-95d3-461c2b2074b2 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-5d260c84-5989-451c-95d3-461c2b2074b2');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-941d932b-df52-45cc-b016-535f9e6a799c\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-941d932b-df52-45cc-b016-535f9e6a799c')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-941d932b-df52-45cc-b016-535f9e6a799c button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   id  MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0   0  2.3859      15.0  3.827160   1.112100      1280.0  2.486989     34.60   \n",
       "1   1  3.7188      17.0  6.013373   1.054217      1504.0  3.813084     38.69   \n",
       "2   2  4.7750      27.0  6.535604   1.103175      1061.0  2.464602     34.71   \n",
       "3   3  2.4138      16.0  3.350203   0.965432      1255.0  2.089286     32.66   \n",
       "4   4  3.7500      52.0  4.284404   1.069246      1793.0  1.604790     37.80   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -120.12        0.980  \n",
       "1    -121.22        0.946  \n",
       "2    -120.45        1.576  \n",
       "3    -117.09        1.336  \n",
       "4    -122.41        4.500  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "id": "LQhEAGwyntZr",
    "outputId": "6a25c6ed-deac-4080-b19b-b20432d8322b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_39623_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_39623\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_39623_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_39623_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_39623_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_39623_row0_col1\" class=\"data row0 col1\" >5512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_39623_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_39623_row1_col1\" class=\"data row1 col1\" >MedHouseVal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_39623_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_39623_row2_col1\" class=\"data row2 col1\" >Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_39623_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_39623_row3_col1\" class=\"data row3 col1\" >(37137, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_39623_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_39623_row4_col1\" class=\"data row4 col1\" >(37137, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_39623_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_39623_row5_col1\" class=\"data row5 col1\" >(25995, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_39623_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_39623_row6_col1\" class=\"data row6 col1\" >(11142, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_39623_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_39623_row7_col1\" class=\"data row7 col1\" >9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_39623_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_39623_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_39623_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_39623_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_39623_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_39623_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_39623_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_39623_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_39623_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_39623_row12_col1\" class=\"data row12 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_39623_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_39623_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_39623_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_39623_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_39623_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_39623_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_39623_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_39623_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_39623_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_39623_row17_col1\" class=\"data row17 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39623_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_39623_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_39623_row18_col1\" class=\"data row18 col1\" >8945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1413ef3430>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.regression.oop.RegressionExperiment at 0x7f1416022200>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup(data=df,target='MedHouseVal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645,
     "referenced_widgets": [
      "b350b484302e4becba6eb41fd9826be8",
      "8d923bc135a64c1e81874d10b8aceafe",
      "6a4da9af37304feb9164731641f5df6f",
      "cc8f468eda794a8ca0302617f958113d",
      "15a640bae0044561b5b568deab656e24",
      "4fd6c38a079e4a7ea056654f05ccc956",
      "52207eaea9384405be8cbe0279b525ac",
      "1d24289968ef489a846bb98057925ac2",
      "bf104749b1304c5a9fd12bf389ffba5f",
      "61c1a3bcd6b84fdf8f38a02fd8d830d2",
      "5bfa6b63783f4e6c8fdfd3591a80fa33"
     ]
    },
    "id": "PmK8APGuoK8p",
    "outputId": "38c8b48a-2aa0-4bf5-e58f-eeaaa81c1ff9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e32ac th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e32ac_row0_col0, #T_e32ac_row1_col0, #T_e32ac_row1_col1, #T_e32ac_row1_col2, #T_e32ac_row1_col3, #T_e32ac_row1_col4, #T_e32ac_row1_col5, #T_e32ac_row1_col6, #T_e32ac_row2_col0, #T_e32ac_row2_col1, #T_e32ac_row2_col2, #T_e32ac_row2_col3, #T_e32ac_row2_col4, #T_e32ac_row2_col5, #T_e32ac_row2_col6, #T_e32ac_row3_col0, #T_e32ac_row3_col1, #T_e32ac_row3_col2, #T_e32ac_row3_col3, #T_e32ac_row3_col4, #T_e32ac_row3_col5, #T_e32ac_row3_col6, #T_e32ac_row4_col0, #T_e32ac_row4_col1, #T_e32ac_row4_col2, #T_e32ac_row4_col3, #T_e32ac_row4_col4, #T_e32ac_row4_col5, #T_e32ac_row4_col6, #T_e32ac_row5_col0, #T_e32ac_row5_col1, #T_e32ac_row5_col2, #T_e32ac_row5_col3, #T_e32ac_row5_col4, #T_e32ac_row5_col5, #T_e32ac_row5_col6, #T_e32ac_row6_col0, #T_e32ac_row6_col1, #T_e32ac_row6_col2, #T_e32ac_row6_col3, #T_e32ac_row6_col4, #T_e32ac_row6_col5, #T_e32ac_row6_col6, #T_e32ac_row7_col0, #T_e32ac_row7_col1, #T_e32ac_row7_col2, #T_e32ac_row7_col3, #T_e32ac_row7_col4, #T_e32ac_row7_col5, #T_e32ac_row7_col6, #T_e32ac_row8_col0, #T_e32ac_row8_col1, #T_e32ac_row8_col2, #T_e32ac_row8_col3, #T_e32ac_row8_col4, #T_e32ac_row8_col5, #T_e32ac_row8_col6, #T_e32ac_row9_col0, #T_e32ac_row9_col1, #T_e32ac_row9_col2, #T_e32ac_row9_col3, #T_e32ac_row9_col4, #T_e32ac_row9_col5, #T_e32ac_row9_col6, #T_e32ac_row10_col0, #T_e32ac_row10_col1, #T_e32ac_row10_col2, #T_e32ac_row10_col3, #T_e32ac_row10_col4, #T_e32ac_row10_col5, #T_e32ac_row10_col6, #T_e32ac_row11_col0, #T_e32ac_row11_col1, #T_e32ac_row11_col2, #T_e32ac_row11_col3, #T_e32ac_row11_col4, #T_e32ac_row11_col5, #T_e32ac_row11_col6, #T_e32ac_row12_col0, #T_e32ac_row12_col1, #T_e32ac_row12_col2, #T_e32ac_row12_col3, #T_e32ac_row12_col4, #T_e32ac_row12_col5, #T_e32ac_row12_col6, #T_e32ac_row13_col0, #T_e32ac_row13_col1, #T_e32ac_row13_col2, #T_e32ac_row13_col3, #T_e32ac_row13_col4, #T_e32ac_row13_col5, #T_e32ac_row13_col6, #T_e32ac_row14_col0, #T_e32ac_row14_col1, #T_e32ac_row14_col2, #T_e32ac_row14_col3, #T_e32ac_row14_col4, #T_e32ac_row14_col5, #T_e32ac_row14_col6, #T_e32ac_row15_col0, #T_e32ac_row15_col1, #T_e32ac_row15_col2, #T_e32ac_row15_col3, #T_e32ac_row15_col4, #T_e32ac_row15_col5, #T_e32ac_row15_col6, #T_e32ac_row16_col0, #T_e32ac_row16_col1, #T_e32ac_row16_col2, #T_e32ac_row16_col3, #T_e32ac_row16_col4, #T_e32ac_row16_col5, #T_e32ac_row16_col6, #T_e32ac_row17_col0, #T_e32ac_row17_col1, #T_e32ac_row17_col2, #T_e32ac_row17_col3, #T_e32ac_row17_col4, #T_e32ac_row17_col5, #T_e32ac_row17_col6, #T_e32ac_row18_col0, #T_e32ac_row18_col1, #T_e32ac_row18_col2, #T_e32ac_row18_col3, #T_e32ac_row18_col4, #T_e32ac_row18_col5, #T_e32ac_row18_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e32ac_row0_col1, #T_e32ac_row0_col2, #T_e32ac_row0_col3, #T_e32ac_row0_col4, #T_e32ac_row0_col5, #T_e32ac_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_e32ac_row0_col7, #T_e32ac_row1_col7, #T_e32ac_row2_col7, #T_e32ac_row3_col7, #T_e32ac_row4_col7, #T_e32ac_row5_col7, #T_e32ac_row6_col7, #T_e32ac_row7_col7, #T_e32ac_row8_col7, #T_e32ac_row9_col7, #T_e32ac_row10_col7, #T_e32ac_row11_col7, #T_e32ac_row12_col7, #T_e32ac_row13_col7, #T_e32ac_row14_col7, #T_e32ac_row16_col7, #T_e32ac_row17_col7, #T_e32ac_row18_col7 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_e32ac_row15_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e32ac\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e32ac_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_e32ac_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_e32ac_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_e32ac_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_e32ac_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_e32ac_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_e32ac_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "      <th id=\"T_e32ac_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row0\" class=\"row_heading level0 row0\" >lightgbm</th>\n",
       "      <td id=\"T_e32ac_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_e32ac_row0_col1\" class=\"data row0 col1\" >0.4041</td>\n",
       "      <td id=\"T_e32ac_row0_col2\" class=\"data row0 col2\" >0.3256</td>\n",
       "      <td id=\"T_e32ac_row0_col3\" class=\"data row0 col3\" >0.5705</td>\n",
       "      <td id=\"T_e32ac_row0_col4\" class=\"data row0 col4\" >0.7578</td>\n",
       "      <td id=\"T_e32ac_row0_col5\" class=\"data row0 col5\" >0.1714</td>\n",
       "      <td id=\"T_e32ac_row0_col6\" class=\"data row0 col6\" >0.2268</td>\n",
       "      <td id=\"T_e32ac_row0_col7\" class=\"data row0 col7\" >1.1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row1\" class=\"row_heading level0 row1\" >xgboost</th>\n",
       "      <td id=\"T_e32ac_row1_col0\" class=\"data row1 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_e32ac_row1_col1\" class=\"data row1 col1\" >0.4162</td>\n",
       "      <td id=\"T_e32ac_row1_col2\" class=\"data row1 col2\" >0.3424</td>\n",
       "      <td id=\"T_e32ac_row1_col3\" class=\"data row1 col3\" >0.5850</td>\n",
       "      <td id=\"T_e32ac_row1_col4\" class=\"data row1 col4\" >0.7453</td>\n",
       "      <td id=\"T_e32ac_row1_col5\" class=\"data row1 col5\" >0.1770</td>\n",
       "      <td id=\"T_e32ac_row1_col6\" class=\"data row1 col6\" >0.2341</td>\n",
       "      <td id=\"T_e32ac_row1_col7\" class=\"data row1 col7\" >0.4380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row2\" class=\"row_heading level0 row2\" >gbr</th>\n",
       "      <td id=\"T_e32ac_row2_col0\" class=\"data row2 col0\" >Gradient Boosting Regressor</td>\n",
       "      <td id=\"T_e32ac_row2_col1\" class=\"data row2 col1\" >0.4291</td>\n",
       "      <td id=\"T_e32ac_row2_col2\" class=\"data row2 col2\" >0.3566</td>\n",
       "      <td id=\"T_e32ac_row2_col3\" class=\"data row2 col3\" >0.5971</td>\n",
       "      <td id=\"T_e32ac_row2_col4\" class=\"data row2 col4\" >0.7347</td>\n",
       "      <td id=\"T_e32ac_row2_col5\" class=\"data row2 col5\" >0.1802</td>\n",
       "      <td id=\"T_e32ac_row2_col6\" class=\"data row2 col6\" >0.2438</td>\n",
       "      <td id=\"T_e32ac_row2_col7\" class=\"data row2 col7\" >5.9910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row3\" class=\"row_heading level0 row3\" >rf</th>\n",
       "      <td id=\"T_e32ac_row3_col0\" class=\"data row3 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_e32ac_row3_col1\" class=\"data row3 col1\" >0.4243</td>\n",
       "      <td id=\"T_e32ac_row3_col2\" class=\"data row3 col2\" >0.3580</td>\n",
       "      <td id=\"T_e32ac_row3_col3\" class=\"data row3 col3\" >0.5982</td>\n",
       "      <td id=\"T_e32ac_row3_col4\" class=\"data row3 col4\" >0.7336</td>\n",
       "      <td id=\"T_e32ac_row3_col5\" class=\"data row3 col5\" >0.1797</td>\n",
       "      <td id=\"T_e32ac_row3_col6\" class=\"data row3 col6\" >0.2401</td>\n",
       "      <td id=\"T_e32ac_row3_col7\" class=\"data row3 col7\" >18.8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row4\" class=\"row_heading level0 row4\" >et</th>\n",
       "      <td id=\"T_e32ac_row4_col0\" class=\"data row4 col0\" >Extra Trees Regressor</td>\n",
       "      <td id=\"T_e32ac_row4_col1\" class=\"data row4 col1\" >0.4305</td>\n",
       "      <td id=\"T_e32ac_row4_col2\" class=\"data row4 col2\" >0.3665</td>\n",
       "      <td id=\"T_e32ac_row4_col3\" class=\"data row4 col3\" >0.6053</td>\n",
       "      <td id=\"T_e32ac_row4_col4\" class=\"data row4 col4\" >0.7273</td>\n",
       "      <td id=\"T_e32ac_row4_col5\" class=\"data row4 col5\" >0.1803</td>\n",
       "      <td id=\"T_e32ac_row4_col6\" class=\"data row4 col6\" >0.2417</td>\n",
       "      <td id=\"T_e32ac_row4_col7\" class=\"data row4 col7\" >6.6410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row5\" class=\"row_heading level0 row5\" >ada</th>\n",
       "      <td id=\"T_e32ac_row5_col0\" class=\"data row5 col0\" >AdaBoost Regressor</td>\n",
       "      <td id=\"T_e32ac_row5_col1\" class=\"data row5 col1\" >0.6953</td>\n",
       "      <td id=\"T_e32ac_row5_col2\" class=\"data row5 col2\" >0.6847</td>\n",
       "      <td id=\"T_e32ac_row5_col3\" class=\"data row5 col3\" >0.8266</td>\n",
       "      <td id=\"T_e32ac_row5_col4\" class=\"data row5 col4\" >0.4913</td>\n",
       "      <td id=\"T_e32ac_row5_col5\" class=\"data row5 col5\" >0.2748</td>\n",
       "      <td id=\"T_e32ac_row5_col6\" class=\"data row5 col6\" >0.4943</td>\n",
       "      <td id=\"T_e32ac_row5_col7\" class=\"data row5 col7\" >1.3470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row6\" class=\"row_heading level0 row6\" >dt</th>\n",
       "      <td id=\"T_e32ac_row6_col0\" class=\"data row6 col0\" >Decision Tree Regressor</td>\n",
       "      <td id=\"T_e32ac_row6_col1\" class=\"data row6 col1\" >0.5858</td>\n",
       "      <td id=\"T_e32ac_row6_col2\" class=\"data row6 col2\" >0.7111</td>\n",
       "      <td id=\"T_e32ac_row6_col3\" class=\"data row6 col3\" >0.8431</td>\n",
       "      <td id=\"T_e32ac_row6_col4\" class=\"data row6 col4\" >0.4707</td>\n",
       "      <td id=\"T_e32ac_row6_col5\" class=\"data row6 col5\" >0.2505</td>\n",
       "      <td id=\"T_e32ac_row6_col6\" class=\"data row6 col6\" >0.3229</td>\n",
       "      <td id=\"T_e32ac_row6_col7\" class=\"data row6 col7\" >0.2870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row7\" class=\"row_heading level0 row7\" >en</th>\n",
       "      <td id=\"T_e32ac_row7_col0\" class=\"data row7 col0\" >Elastic Net</td>\n",
       "      <td id=\"T_e32ac_row7_col1\" class=\"data row7 col1\" >0.6823</td>\n",
       "      <td id=\"T_e32ac_row7_col2\" class=\"data row7 col2\" >0.7695</td>\n",
       "      <td id=\"T_e32ac_row7_col3\" class=\"data row7 col3\" >0.8770</td>\n",
       "      <td id=\"T_e32ac_row7_col4\" class=\"data row7 col4\" >0.4281</td>\n",
       "      <td id=\"T_e32ac_row7_col5\" class=\"data row7 col5\" >0.2777</td>\n",
       "      <td id=\"T_e32ac_row7_col6\" class=\"data row7 col6\" >0.4554</td>\n",
       "      <td id=\"T_e32ac_row7_col7\" class=\"data row7 col7\" >0.0380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row8\" class=\"row_heading level0 row8\" >llar</th>\n",
       "      <td id=\"T_e32ac_row8_col0\" class=\"data row8 col0\" >Lasso Least Angle Regression</td>\n",
       "      <td id=\"T_e32ac_row8_col1\" class=\"data row8 col1\" >0.7750</td>\n",
       "      <td id=\"T_e32ac_row8_col2\" class=\"data row8 col2\" >0.9662</td>\n",
       "      <td id=\"T_e32ac_row8_col3\" class=\"data row8 col3\" >0.9827</td>\n",
       "      <td id=\"T_e32ac_row8_col4\" class=\"data row8 col4\" >0.2820</td>\n",
       "      <td id=\"T_e32ac_row8_col5\" class=\"data row8 col5\" >0.3101</td>\n",
       "      <td id=\"T_e32ac_row8_col6\" class=\"data row8 col6\" >0.5260</td>\n",
       "      <td id=\"T_e32ac_row8_col7\" class=\"data row8 col7\" >0.0360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row9\" class=\"row_heading level0 row9\" >lasso</th>\n",
       "      <td id=\"T_e32ac_row9_col0\" class=\"data row9 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_e32ac_row9_col1\" class=\"data row9 col1\" >0.7750</td>\n",
       "      <td id=\"T_e32ac_row9_col2\" class=\"data row9 col2\" >0.9662</td>\n",
       "      <td id=\"T_e32ac_row9_col3\" class=\"data row9 col3\" >0.9827</td>\n",
       "      <td id=\"T_e32ac_row9_col4\" class=\"data row9 col4\" >0.2820</td>\n",
       "      <td id=\"T_e32ac_row9_col5\" class=\"data row9 col5\" >0.3101</td>\n",
       "      <td id=\"T_e32ac_row9_col6\" class=\"data row9 col6\" >0.5260</td>\n",
       "      <td id=\"T_e32ac_row9_col7\" class=\"data row9 col7\" >0.0360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row10\" class=\"row_heading level0 row10\" >lar</th>\n",
       "      <td id=\"T_e32ac_row10_col0\" class=\"data row10 col0\" >Least Angle Regression</td>\n",
       "      <td id=\"T_e32ac_row10_col1\" class=\"data row10 col1\" >0.5385</td>\n",
       "      <td id=\"T_e32ac_row10_col2\" class=\"data row10 col2\" >1.0329</td>\n",
       "      <td id=\"T_e32ac_row10_col3\" class=\"data row10 col3\" >0.8907</td>\n",
       "      <td id=\"T_e32ac_row10_col4\" class=\"data row10 col4\" >0.2263</td>\n",
       "      <td id=\"T_e32ac_row10_col5\" class=\"data row10 col5\" >0.2207</td>\n",
       "      <td id=\"T_e32ac_row10_col6\" class=\"data row10 col6\" >0.3119</td>\n",
       "      <td id=\"T_e32ac_row10_col7\" class=\"data row10 col7\" >0.0380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row11\" class=\"row_heading level0 row11\" >lr</th>\n",
       "      <td id=\"T_e32ac_row11_col0\" class=\"data row11 col0\" >Linear Regression</td>\n",
       "      <td id=\"T_e32ac_row11_col1\" class=\"data row11 col1\" >0.5375</td>\n",
       "      <td id=\"T_e32ac_row11_col2\" class=\"data row11 col2\" >1.0529</td>\n",
       "      <td id=\"T_e32ac_row11_col3\" class=\"data row11 col3\" >0.8933</td>\n",
       "      <td id=\"T_e32ac_row11_col4\" class=\"data row11 col4\" >0.2112</td>\n",
       "      <td id=\"T_e32ac_row11_col5\" class=\"data row11 col5\" >0.2198</td>\n",
       "      <td id=\"T_e32ac_row11_col6\" class=\"data row11 col6\" >0.3132</td>\n",
       "      <td id=\"T_e32ac_row11_col7\" class=\"data row11 col7\" >0.7960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row12\" class=\"row_heading level0 row12\" >ridge</th>\n",
       "      <td id=\"T_e32ac_row12_col0\" class=\"data row12 col0\" >Ridge Regression</td>\n",
       "      <td id=\"T_e32ac_row12_col1\" class=\"data row12 col1\" >0.5375</td>\n",
       "      <td id=\"T_e32ac_row12_col2\" class=\"data row12 col2\" >1.0530</td>\n",
       "      <td id=\"T_e32ac_row12_col3\" class=\"data row12 col3\" >0.8933</td>\n",
       "      <td id=\"T_e32ac_row12_col4\" class=\"data row12 col4\" >0.2111</td>\n",
       "      <td id=\"T_e32ac_row12_col5\" class=\"data row12 col5\" >0.2198</td>\n",
       "      <td id=\"T_e32ac_row12_col6\" class=\"data row12 col6\" >0.3132</td>\n",
       "      <td id=\"T_e32ac_row12_col7\" class=\"data row12 col7\" >0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row13\" class=\"row_heading level0 row13\" >br</th>\n",
       "      <td id=\"T_e32ac_row13_col0\" class=\"data row13 col0\" >Bayesian Ridge</td>\n",
       "      <td id=\"T_e32ac_row13_col1\" class=\"data row13 col1\" >0.5375</td>\n",
       "      <td id=\"T_e32ac_row13_col2\" class=\"data row13 col2\" >1.0532</td>\n",
       "      <td id=\"T_e32ac_row13_col3\" class=\"data row13 col3\" >0.8934</td>\n",
       "      <td id=\"T_e32ac_row13_col4\" class=\"data row13 col4\" >0.2109</td>\n",
       "      <td id=\"T_e32ac_row13_col5\" class=\"data row13 col5\" >0.2198</td>\n",
       "      <td id=\"T_e32ac_row13_col6\" class=\"data row13 col6\" >0.3132</td>\n",
       "      <td id=\"T_e32ac_row13_col7\" class=\"data row13 col7\" >0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row14\" class=\"row_heading level0 row14\" >omp</th>\n",
       "      <td id=\"T_e32ac_row14_col0\" class=\"data row14 col0\" >Orthogonal Matching Pursuit</td>\n",
       "      <td id=\"T_e32ac_row14_col1\" class=\"data row14 col1\" >0.9181</td>\n",
       "      <td id=\"T_e32ac_row14_col2\" class=\"data row14 col2\" >1.3441</td>\n",
       "      <td id=\"T_e32ac_row14_col3\" class=\"data row14 col3\" >1.1591</td>\n",
       "      <td id=\"T_e32ac_row14_col4\" class=\"data row14 col4\" >0.0010</td>\n",
       "      <td id=\"T_e32ac_row14_col5\" class=\"data row14 col5\" >0.3638</td>\n",
       "      <td id=\"T_e32ac_row14_col6\" class=\"data row14 col6\" >0.6280</td>\n",
       "      <td id=\"T_e32ac_row14_col7\" class=\"data row14 col7\" >0.0340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row15\" class=\"row_heading level0 row15\" >dummy</th>\n",
       "      <td id=\"T_e32ac_row15_col0\" class=\"data row15 col0\" >Dummy Regressor</td>\n",
       "      <td id=\"T_e32ac_row15_col1\" class=\"data row15 col1\" >0.9186</td>\n",
       "      <td id=\"T_e32ac_row15_col2\" class=\"data row15 col2\" >1.3458</td>\n",
       "      <td id=\"T_e32ac_row15_col3\" class=\"data row15 col3\" >1.1599</td>\n",
       "      <td id=\"T_e32ac_row15_col4\" class=\"data row15 col4\" >-0.0003</td>\n",
       "      <td id=\"T_e32ac_row15_col5\" class=\"data row15 col5\" >0.3637</td>\n",
       "      <td id=\"T_e32ac_row15_col6\" class=\"data row15 col6\" >0.6270</td>\n",
       "      <td id=\"T_e32ac_row15_col7\" class=\"data row15 col7\" >0.0310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row16\" class=\"row_heading level0 row16\" >knn</th>\n",
       "      <td id=\"T_e32ac_row16_col0\" class=\"data row16 col0\" >K Neighbors Regressor</td>\n",
       "      <td id=\"T_e32ac_row16_col1\" class=\"data row16 col1\" >0.9933</td>\n",
       "      <td id=\"T_e32ac_row16_col2\" class=\"data row16 col2\" >1.6006</td>\n",
       "      <td id=\"T_e32ac_row16_col3\" class=\"data row16 col3\" >1.2650</td>\n",
       "      <td id=\"T_e32ac_row16_col4\" class=\"data row16 col4\" >-0.1899</td>\n",
       "      <td id=\"T_e32ac_row16_col5\" class=\"data row16 col5\" >0.3975</td>\n",
       "      <td id=\"T_e32ac_row16_col6\" class=\"data row16 col6\" >0.6689</td>\n",
       "      <td id=\"T_e32ac_row16_col7\" class=\"data row16 col7\" >0.1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row17\" class=\"row_heading level0 row17\" >huber</th>\n",
       "      <td id=\"T_e32ac_row17_col0\" class=\"data row17 col0\" >Huber Regressor</td>\n",
       "      <td id=\"T_e32ac_row17_col1\" class=\"data row17 col1\" >0.5595</td>\n",
       "      <td id=\"T_e32ac_row17_col2\" class=\"data row17 col2\" >1.6069</td>\n",
       "      <td id=\"T_e32ac_row17_col3\" class=\"data row17 col3\" >1.0209</td>\n",
       "      <td id=\"T_e32ac_row17_col4\" class=\"data row17 col4\" >-0.2062</td>\n",
       "      <td id=\"T_e32ac_row17_col5\" class=\"data row17 col5\" >0.2314</td>\n",
       "      <td id=\"T_e32ac_row17_col6\" class=\"data row17 col6\" >0.3162</td>\n",
       "      <td id=\"T_e32ac_row17_col7\" class=\"data row17 col7\" >0.3140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e32ac_level0_row18\" class=\"row_heading level0 row18\" >par</th>\n",
       "      <td id=\"T_e32ac_row18_col0\" class=\"data row18 col0\" >Passive Aggressive Regressor</td>\n",
       "      <td id=\"T_e32ac_row18_col1\" class=\"data row18 col1\" >3.3387</td>\n",
       "      <td id=\"T_e32ac_row18_col2\" class=\"data row18 col2\" >34.1358</td>\n",
       "      <td id=\"T_e32ac_row18_col3\" class=\"data row18 col3\" >4.0475</td>\n",
       "      <td id=\"T_e32ac_row18_col4\" class=\"data row18 col4\" >-23.5322</td>\n",
       "      <td id=\"T_e32ac_row18_col5\" class=\"data row18 col5\" >0.6215</td>\n",
       "      <td id=\"T_e32ac_row18_col6\" class=\"data row18 col6\" >2.0030</td>\n",
       "      <td id=\"T_e32ac_row18_col7\" class=\"data row18 col7\" >0.0680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f141ba181c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b350b484302e4becba6eb41fd9826be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model=compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9X58JQLBCFz2"
   },
   "outputs": [],
   "source": [
    "#%75 başarı oaranını daha yukarı çekmek için deep learning kullanalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HG5UN4Nf8nH",
    "outputId": "e46dac3d-a690-4901-d271-cd85fef697ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "v_UuiKabf8tr"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Yg7LfAqLf8v8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GCEu37F8f8yO"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vdtqvnTfgSiA"
   },
   "outputs": [],
   "source": [
    "x=df.drop('MedHouseVal',axis=1)\n",
    "y=df[['MedHouseVal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wv5iJ8VogMBS"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2VoqaYaJfpu4"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(1))   #regression olduğu için sadece Dense(1) yazdık. Tek bir değer tahmin edeceğiz\n",
    "model.compile(loss='mse', optimizer='adam')  #mes mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PS4hele4gflE",
    "outputId": "bca5091a-d482-46f1-dcff-769c79634e47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "233/233 [==============================] - 3s 4ms/step - loss: 631.8372 - val_loss: 7.1972\n",
      "Epoch 2/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 4.0430 - val_loss: 2.1739\n",
      "Epoch 3/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.9896 - val_loss: 2.1773\n",
      "Epoch 4/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 1.6955 - val_loss: 1.6790\n",
      "Epoch 5/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 1.7560 - val_loss: 2.9815\n",
      "Epoch 6/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 4.9238 - val_loss: 1.9759\n",
      "Epoch 7/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 1.8791 - val_loss: 3.7619\n",
      "Epoch 8/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 1.7186 - val_loss: 1.5622\n",
      "Epoch 9/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 1.7254 - val_loss: 1.5420\n",
      "Epoch 10/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.6839 - val_loss: 2.3716\n",
      "Epoch 11/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.8134 - val_loss: 1.8177\n",
      "Epoch 12/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.7971 - val_loss: 4.9192\n",
      "Epoch 13/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 2.4259 - val_loss: 8.8281\n",
      "Epoch 14/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 6.2438 - val_loss: 2.9058\n",
      "Epoch 15/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 5.9750 - val_loss: 2.0840\n",
      "Epoch 16/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 5.1307 - val_loss: 20.7234\n",
      "Epoch 17/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 4.2367 - val_loss: 50.7649\n",
      "Epoch 18/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 6.4225 - val_loss: 2.3479\n",
      "Epoch 19/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 3.6061 - val_loss: 8.5268\n",
      "Epoch 20/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 8.2201 - val_loss: 1.2580\n",
      "Epoch 21/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 3.0305 - val_loss: 5.1039\n",
      "Epoch 22/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 4.1387 - val_loss: 1.1851\n",
      "Epoch 23/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 9.1128 - val_loss: 3.2123\n",
      "Epoch 24/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 3.7947 - val_loss: 1.4399\n",
      "Epoch 25/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 2.0968 - val_loss: 4.2556\n",
      "Epoch 26/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 5.6078 - val_loss: 932.9409\n",
      "Epoch 27/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 24.6339 - val_loss: 1.2815\n",
      "Epoch 28/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 1.2467 - val_loss: 3.3191\n",
      "Epoch 29/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.4632 - val_loss: 1.0700\n",
      "Epoch 30/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.7611 - val_loss: 1.2892\n",
      "Epoch 31/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.7906 - val_loss: 1.0314\n",
      "Epoch 32/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 2.7235 - val_loss: 1.8617\n",
      "Epoch 33/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 2.3057 - val_loss: 18.9782\n",
      "Epoch 34/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 3.6505 - val_loss: 6.7975\n",
      "Epoch 35/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 4.1390 - val_loss: 2.8173\n",
      "Epoch 36/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 4.1081 - val_loss: 3.9201\n",
      "Epoch 37/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.9916 - val_loss: 9.5796\n",
      "Epoch 38/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 2.6472 - val_loss: 4.1475\n",
      "Epoch 39/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 2.2384 - val_loss: 4.0152\n",
      "Epoch 40/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 2.0029 - val_loss: 7.7965\n",
      "Epoch 41/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 2.4900 - val_loss: 7.3796\n",
      "Epoch 42/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 2.3076 - val_loss: 1.0109\n",
      "Epoch 43/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 1.9420 - val_loss: 2.1759\n",
      "Epoch 44/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 2.2968 - val_loss: 2.0652\n",
      "Epoch 45/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 2.0621 - val_loss: 2.5430\n",
      "Epoch 46/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 2.6197 - val_loss: 2.5877\n",
      "Epoch 47/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 1.8393 - val_loss: 2.5443\n",
      "Epoch 48/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 2.0071 - val_loss: 1.1155\n",
      "Epoch 49/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.7459 - val_loss: 0.9349\n",
      "Epoch 50/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.6389 - val_loss: 1.3378\n",
      "Epoch 51/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.8157 - val_loss: 14.4799\n",
      "Epoch 52/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 2.4969 - val_loss: 1.4523\n",
      "Epoch 53/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.2155 - val_loss: 1.7371\n",
      "Epoch 54/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 1.7717 - val_loss: 2.0094\n",
      "Epoch 55/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 1.2478 - val_loss: 1.4951\n",
      "Epoch 56/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 1.2901 - val_loss: 6.8450\n",
      "Epoch 57/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.6644 - val_loss: 0.9618\n",
      "Epoch 58/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.6689 - val_loss: 0.9234\n",
      "Epoch 59/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 1.1513 - val_loss: 1.0575\n",
      "Epoch 60/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 1.3226 - val_loss: 1.8057\n",
      "Epoch 61/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 1.3910 - val_loss: 0.8425\n",
      "Epoch 62/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 1.4437 - val_loss: 1.0622\n",
      "Epoch 63/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 1.3352 - val_loss: 2.3863\n",
      "Epoch 64/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 1.0706 - val_loss: 0.7746\n",
      "Epoch 65/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 1.1205 - val_loss: 1.6918\n",
      "Epoch 66/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 1.2402 - val_loss: 0.8631\n",
      "Epoch 67/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 1.1987 - val_loss: 1.6631\n",
      "Epoch 68/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 1.1758 - val_loss: 0.7876\n",
      "Epoch 69/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 1.2372 - val_loss: 1.3678\n",
      "Epoch 70/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.8953 - val_loss: 0.7871\n",
      "Epoch 71/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.1199 - val_loss: 0.7509\n",
      "Epoch 72/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.2327 - val_loss: 1.4462\n",
      "Epoch 73/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.0892 - val_loss: 0.9878\n",
      "Epoch 74/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.9899 - val_loss: 0.8094\n",
      "Epoch 75/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.0075 - val_loss: 3.1871\n",
      "Epoch 76/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 1.0126 - val_loss: 1.1459\n",
      "Epoch 77/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 1.0167 - val_loss: 0.8121\n",
      "Epoch 78/300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.9617 - val_loss: 1.0607\n",
      "Epoch 79/300\n",
      "233/233 [==============================] - 2s 9ms/step - loss: 1.1941 - val_loss: 0.8263\n",
      "Epoch 80/300\n",
      "233/233 [==============================] - 2s 7ms/step - loss: 0.9461 - val_loss: 1.1252\n",
      "Epoch 81/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.9683 - val_loss: 1.0799\n",
      "Epoch 82/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.9425 - val_loss: 1.6641\n",
      "Epoch 83/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8909 - val_loss: 1.5101\n",
      "Epoch 84/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.9491 - val_loss: 0.9677\n",
      "Epoch 85/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.9164 - val_loss: 1.0400\n",
      "Epoch 86/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.9662 - val_loss: 0.7826\n",
      "Epoch 87/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.8633 - val_loss: 0.7271\n",
      "Epoch 88/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.9175 - val_loss: 1.5651\n",
      "Epoch 89/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8708 - val_loss: 0.8170\n",
      "Epoch 90/300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.8102 - val_loss: 3.1713\n",
      "Epoch 91/300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.9392 - val_loss: 1.5634\n",
      "Epoch 92/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.8474 - val_loss: 0.9167\n",
      "Epoch 93/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.8437 - val_loss: 0.7856\n",
      "Epoch 94/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.8523 - val_loss: 0.8650\n",
      "Epoch 95/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.8298 - val_loss: 1.3113\n",
      "Epoch 96/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.8354 - val_loss: 0.8132\n",
      "Epoch 97/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.8428 - val_loss: 0.7003\n",
      "Epoch 98/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 4.6484 - val_loss: 0.7801\n",
      "Epoch 99/300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.7439 - val_loss: 0.8500\n",
      "Epoch 100/300\n",
      "233/233 [==============================] - 2s 8ms/step - loss: 0.7261 - val_loss: 0.7117\n",
      "Epoch 101/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7206 - val_loss: 0.9676\n",
      "Epoch 102/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7549 - val_loss: 0.7052\n",
      "Epoch 103/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7422 - val_loss: 0.7559\n",
      "Epoch 104/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7471 - val_loss: 0.8402\n",
      "Epoch 105/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7764 - val_loss: 1.0167\n",
      "Epoch 106/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7668 - val_loss: 0.8018\n",
      "Epoch 107/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7143 - val_loss: 0.7086\n",
      "Epoch 108/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7510 - val_loss: 0.6999\n",
      "Epoch 109/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7433 - val_loss: 0.7317\n",
      "Epoch 110/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7500 - val_loss: 1.4444\n",
      "Epoch 111/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.8102 - val_loss: 1.5732\n",
      "Epoch 112/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7830 - val_loss: 1.3311\n",
      "Epoch 113/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.7898 - val_loss: 0.8587\n",
      "Epoch 114/300\n",
      "233/233 [==============================] - 2s 8ms/step - loss: 0.7191 - val_loss: 0.7158\n",
      "Epoch 115/300\n",
      "233/233 [==============================] - 2s 7ms/step - loss: 0.7419 - val_loss: 0.6809\n",
      "Epoch 116/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.7379 - val_loss: 0.7428\n",
      "Epoch 117/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.7144 - val_loss: 0.6884\n",
      "Epoch 118/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.7313 - val_loss: 1.3248\n",
      "Epoch 119/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7401 - val_loss: 0.7261\n",
      "Epoch 120/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7227 - val_loss: 0.7229\n",
      "Epoch 121/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6967 - val_loss: 0.6722\n",
      "Epoch 122/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7134 - val_loss: 0.7790\n",
      "Epoch 123/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7297 - val_loss: 0.8030\n",
      "Epoch 124/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7510 - val_loss: 0.6862\n",
      "Epoch 125/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7099 - val_loss: 0.9480\n",
      "Epoch 126/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6913 - val_loss: 1.0377\n",
      "Epoch 127/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6841 - val_loss: 0.8653\n",
      "Epoch 128/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7346 - val_loss: 0.7051\n",
      "Epoch 129/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7691 - val_loss: 1.4826\n",
      "Epoch 130/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.8711 - val_loss: 0.7544\n",
      "Epoch 131/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7135 - val_loss: 0.8101\n",
      "Epoch 132/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7555 - val_loss: 0.6735\n",
      "Epoch 133/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6965 - val_loss: 0.6873\n",
      "Epoch 134/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6932 - val_loss: 0.7154\n",
      "Epoch 135/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6813 - val_loss: 0.8683\n",
      "Epoch 136/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.7054 - val_loss: 0.9948\n",
      "Epoch 137/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6880 - val_loss: 0.6550\n",
      "Epoch 138/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6666 - val_loss: 0.7478\n",
      "Epoch 139/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.6942 - val_loss: 0.6627\n",
      "Epoch 140/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7172 - val_loss: 0.6471\n",
      "Epoch 141/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7114 - val_loss: 0.8313\n",
      "Epoch 142/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6636 - val_loss: 0.7790\n",
      "Epoch 143/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7223 - val_loss: 0.8126\n",
      "Epoch 144/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6880 - val_loss: 1.0225\n",
      "Epoch 145/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6887 - val_loss: 0.6668\n",
      "Epoch 146/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6782 - val_loss: 0.7017\n",
      "Epoch 147/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6722 - val_loss: 0.6634\n",
      "Epoch 148/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6594 - val_loss: 0.6453\n",
      "Epoch 149/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6874 - val_loss: 0.9147\n",
      "Epoch 150/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7016 - val_loss: 0.7326\n",
      "Epoch 151/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6844 - val_loss: 0.8872\n",
      "Epoch 152/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6624 - val_loss: 0.7400\n",
      "Epoch 153/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6545 - val_loss: 0.7006\n",
      "Epoch 154/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6811 - val_loss: 0.6821\n",
      "Epoch 155/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6821 - val_loss: 0.6918\n",
      "Epoch 156/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6555 - val_loss: 0.9453\n",
      "Epoch 157/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6864 - val_loss: 0.9738\n",
      "Epoch 158/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6625 - val_loss: 0.9395\n",
      "Epoch 159/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.6527 - val_loss: 0.6234\n",
      "Epoch 160/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6898 - val_loss: 0.6172\n",
      "Epoch 161/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6436 - val_loss: 1.2461\n",
      "Epoch 162/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6450 - val_loss: 0.8070\n",
      "Epoch 163/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6682 - val_loss: 0.9457\n",
      "Epoch 164/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.7507 - val_loss: 1.1937\n",
      "Epoch 165/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6917 - val_loss: 0.6342\n",
      "Epoch 166/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6544 - val_loss: 0.6738\n",
      "Epoch 167/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6562 - val_loss: 0.9385\n",
      "Epoch 168/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6538 - val_loss: 0.8812\n",
      "Epoch 169/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6761 - val_loss: 0.6568\n",
      "Epoch 170/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6574 - val_loss: 0.6240\n",
      "Epoch 171/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6565 - val_loss: 0.6805\n",
      "Epoch 172/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6293 - val_loss: 1.0105\n",
      "Epoch 173/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6679 - val_loss: 0.7343\n",
      "Epoch 174/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6368 - val_loss: 0.7139\n",
      "Epoch 175/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6720 - val_loss: 0.6749\n",
      "Epoch 176/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6313 - val_loss: 0.6291\n",
      "Epoch 177/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6303 - val_loss: 0.8465\n",
      "Epoch 178/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.6502 - val_loss: 0.6153\n",
      "Epoch 179/300\n",
      "233/233 [==============================] - 2s 7ms/step - loss: 0.6166 - val_loss: 0.7412\n",
      "Epoch 180/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6303 - val_loss: 0.6131\n",
      "Epoch 181/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6242 - val_loss: 0.6877\n",
      "Epoch 182/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6534 - val_loss: 1.1586\n",
      "Epoch 183/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6743 - val_loss: 0.6583\n",
      "Epoch 184/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6528 - val_loss: 0.6304\n",
      "Epoch 185/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6419 - val_loss: 0.6353\n",
      "Epoch 186/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6296 - val_loss: 0.8785\n",
      "Epoch 187/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6560 - val_loss: 0.6658\n",
      "Epoch 188/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6604 - val_loss: 0.7712\n",
      "Epoch 189/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6134 - val_loss: 1.5849\n",
      "Epoch 190/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6223 - val_loss: 0.8787\n",
      "Epoch 191/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6123 - val_loss: 0.6169\n",
      "Epoch 192/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6284 - val_loss: 0.7397\n",
      "Epoch 193/300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.6426 - val_loss: 0.8383\n",
      "Epoch 194/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5989 - val_loss: 0.6103\n",
      "Epoch 195/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6262 - val_loss: 0.7292\n",
      "Epoch 196/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6118 - val_loss: 0.8506\n",
      "Epoch 197/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6165 - val_loss: 0.7372\n",
      "Epoch 198/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6069 - val_loss: 1.1657\n",
      "Epoch 199/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6086 - val_loss: 0.5901\n",
      "Epoch 200/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6238 - val_loss: 0.7904\n",
      "Epoch 201/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6401 - val_loss: 0.5927\n",
      "Epoch 202/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6207 - val_loss: 0.5983\n",
      "Epoch 203/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6246 - val_loss: 0.6125\n",
      "Epoch 204/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6045 - val_loss: 0.5938\n",
      "Epoch 205/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6272 - val_loss: 0.7937\n",
      "Epoch 206/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5983 - val_loss: 0.6151\n",
      "Epoch 207/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6015 - val_loss: 0.5931\n",
      "Epoch 208/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6138 - val_loss: 0.8043\n",
      "Epoch 209/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6092 - val_loss: 0.6566\n",
      "Epoch 210/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5910 - val_loss: 0.6981\n",
      "Epoch 211/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5902 - val_loss: 1.2223\n",
      "Epoch 212/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6198 - val_loss: 0.5992\n",
      "Epoch 213/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5853 - val_loss: 0.6439\n",
      "Epoch 214/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5907 - val_loss: 0.6405\n",
      "Epoch 215/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5998 - val_loss: 0.5872\n",
      "Epoch 216/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.6069 - val_loss: 0.5817\n",
      "Epoch 217/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5710 - val_loss: 0.6511\n",
      "Epoch 218/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6167 - val_loss: 0.7199\n",
      "Epoch 219/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5783 - val_loss: 0.6062\n",
      "Epoch 220/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5869 - val_loss: 0.7827\n",
      "Epoch 221/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5947 - val_loss: 0.5880\n",
      "Epoch 222/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6008 - val_loss: 0.9013\n",
      "Epoch 223/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5747 - val_loss: 1.6108\n",
      "Epoch 224/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6070 - val_loss: 1.0079\n",
      "Epoch 225/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6077 - val_loss: 0.7109\n",
      "Epoch 226/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6059 - val_loss: 0.6744\n",
      "Epoch 227/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5889 - val_loss: 0.7154\n",
      "Epoch 228/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5772 - val_loss: 0.8220\n",
      "Epoch 229/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5981 - val_loss: 0.6461\n",
      "Epoch 230/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6211 - val_loss: 0.7102\n",
      "Epoch 231/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5955 - val_loss: 0.5916\n",
      "Epoch 232/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5866 - val_loss: 0.8238\n",
      "Epoch 233/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5997 - val_loss: 0.5912\n",
      "Epoch 234/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5718 - val_loss: 0.6076\n",
      "Epoch 235/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5871 - val_loss: 0.5743\n",
      "Epoch 236/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5897 - val_loss: 0.6209\n",
      "Epoch 237/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5754 - val_loss: 0.7466\n",
      "Epoch 238/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5734 - val_loss: 0.6489\n",
      "Epoch 239/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5660 - val_loss: 0.7043\n",
      "Epoch 240/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5759 - val_loss: 0.5837\n",
      "Epoch 241/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5719 - val_loss: 0.8057\n",
      "Epoch 242/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5933 - val_loss: 0.6716\n",
      "Epoch 243/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5800 - val_loss: 1.0411\n",
      "Epoch 244/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5797 - val_loss: 0.5746\n",
      "Epoch 245/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6054 - val_loss: 0.5880\n",
      "Epoch 246/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5859 - val_loss: 0.6021\n",
      "Epoch 247/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5634 - val_loss: 0.6404\n",
      "Epoch 248/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5887 - val_loss: 0.5827\n",
      "Epoch 249/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5805 - val_loss: 0.5682\n",
      "Epoch 250/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5572 - val_loss: 0.6168\n",
      "Epoch 251/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5732 - val_loss: 0.5859\n",
      "Epoch 252/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5633 - val_loss: 0.5751\n",
      "Epoch 253/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5514 - val_loss: 0.5616\n",
      "Epoch 254/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5666 - val_loss: 0.6152\n",
      "Epoch 255/300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5978 - val_loss: 0.9088\n",
      "Epoch 256/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5786 - val_loss: 0.5650\n",
      "Epoch 257/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5702 - val_loss: 0.5683\n",
      "Epoch 258/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5707 - val_loss: 0.5756\n",
      "Epoch 259/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5574 - val_loss: 0.7097\n",
      "Epoch 260/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5631 - val_loss: 0.5775\n",
      "Epoch 261/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5815 - val_loss: 0.6042\n",
      "Epoch 262/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5753 - val_loss: 0.9186\n",
      "Epoch 263/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5751 - val_loss: 0.9536\n",
      "Epoch 264/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5526 - val_loss: 0.5791\n",
      "Epoch 265/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5394 - val_loss: 0.5951\n",
      "Epoch 266/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5770 - val_loss: 0.5852\n",
      "Epoch 267/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5621 - val_loss: 0.5777\n",
      "Epoch 268/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5479 - val_loss: 0.6089\n",
      "Epoch 269/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5684 - val_loss: 0.5683\n",
      "Epoch 270/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5703 - val_loss: 0.8012\n",
      "Epoch 271/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5987 - val_loss: 0.6441\n",
      "Epoch 272/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5557 - val_loss: 0.5743\n",
      "Epoch 273/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5729 - val_loss: 0.7550\n",
      "Epoch 274/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5558 - val_loss: 0.5615\n",
      "Epoch 275/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5582 - val_loss: 0.5579\n",
      "Epoch 276/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5692 - val_loss: 0.8480\n",
      "Epoch 277/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5935 - val_loss: 0.6442\n",
      "Epoch 278/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5733 - val_loss: 0.5606\n",
      "Epoch 279/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5573 - val_loss: 0.6241\n",
      "Epoch 280/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5771 - val_loss: 0.6461\n",
      "Epoch 281/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5996 - val_loss: 0.6130\n",
      "Epoch 282/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5450 - val_loss: 0.5592\n",
      "Epoch 283/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5675 - val_loss: 0.6205\n",
      "Epoch 284/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5627 - val_loss: 0.6723\n",
      "Epoch 285/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5647 - val_loss: 0.7745\n",
      "Epoch 286/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5601 - val_loss: 0.5573\n",
      "Epoch 287/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5637 - val_loss: 0.5591\n",
      "Epoch 288/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5732 - val_loss: 0.5600\n",
      "Epoch 289/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5958 - val_loss: 0.6361\n",
      "Epoch 290/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5731 - val_loss: 0.5648\n",
      "Epoch 291/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5629 - val_loss: 0.5575\n",
      "Epoch 292/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5556 - val_loss: 0.5909\n",
      "Epoch 293/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5569 - val_loss: 0.6110\n",
      "Epoch 294/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5543 - val_loss: 0.5539\n",
      "Epoch 295/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5506 - val_loss: 0.5904\n",
      "Epoch 296/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5518 - val_loss: 0.6112\n",
      "Epoch 297/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.6171 - val_loss: 0.8234\n",
      "Epoch 298/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5502 - val_loss: 0.6631\n",
      "Epoch 299/300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5792 - val_loss: 0.5702\n",
      "Epoch 300/300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5671 - val_loss: 0.6172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f141c25a920>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=128,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PtcWjDFkggkH",
    "outputId": "4034ba85-9ba2-42c9-ecfb-7226f587dc3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 19)                190       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 19)                380       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 19)                380       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 19)                380       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 19)                380       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1730 (6.76 KB)\n",
      "Trainable params: 1730 (6.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6pCqCzIDgstq"
   },
   "outputs": [],
   "source": [
    "loss_df=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "CBYZE10cgu3l",
    "outputId": "a96fd0ee-d38a-473d-823d-61dce1899068"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wfbxplobgwwe",
    "outputId": "188c6641-fc75-48a7-f3d8-dcdc4cbe5a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/233 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "k3Pf_-8vgzyq"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZ47JDApg2Ht",
    "outputId": "15bae82e-a6f5-4883-87f9-f9097dd85250"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5459888290923837"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,tahmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kbKufyBug45p",
    "outputId": "ef5f50e1-686e-4ed7-e22b-503c1329b3bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1300\n",
      "233/233 [==============================] - 4s 15ms/step - loss: 0.5565 - val_loss: 0.5838\n",
      "Epoch 2/1300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.5654 - val_loss: 0.5537\n",
      "Epoch 3/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5566 - val_loss: 0.5590\n",
      "Epoch 4/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5396 - val_loss: 0.5519\n",
      "Epoch 5/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5405 - val_loss: 1.1900\n",
      "Epoch 6/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5791 - val_loss: 0.6239\n",
      "Epoch 7/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5410 - val_loss: 0.5520\n",
      "Epoch 8/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5577 - val_loss: 0.6019\n",
      "Epoch 9/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5419 - val_loss: 0.6287\n",
      "Epoch 10/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5499 - val_loss: 0.8151\n",
      "Epoch 11/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5832 - val_loss: 0.6986\n",
      "Epoch 12/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5466 - val_loss: 0.5546\n",
      "Epoch 13/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5521 - val_loss: 0.7723\n",
      "Epoch 14/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5638 - val_loss: 0.5614\n",
      "Epoch 15/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5686 - val_loss: 0.6832\n",
      "Epoch 16/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5722 - val_loss: 0.6421\n",
      "Epoch 17/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5606 - val_loss: 0.5702\n",
      "Epoch 18/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5653 - val_loss: 0.5945\n",
      "Epoch 19/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5469 - val_loss: 0.8206\n",
      "Epoch 20/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5421 - val_loss: 0.7210\n",
      "Epoch 21/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5482 - val_loss: 0.6009\n",
      "Epoch 22/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5447 - val_loss: 0.5917\n",
      "Epoch 23/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5655 - val_loss: 0.6546\n",
      "Epoch 24/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5635 - val_loss: 0.7702\n",
      "Epoch 25/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5517 - val_loss: 0.5576\n",
      "Epoch 26/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5443 - val_loss: 0.9681\n",
      "Epoch 27/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5509 - val_loss: 0.5550\n",
      "Epoch 28/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5426 - val_loss: 0.5541\n",
      "Epoch 29/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5525 - val_loss: 0.6872\n",
      "Epoch 30/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5626 - val_loss: 0.6651\n",
      "Epoch 31/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5512 - val_loss: 0.5831\n",
      "Epoch 32/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5342 - val_loss: 0.5901\n",
      "Epoch 33/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5603 - val_loss: 0.5823\n",
      "Epoch 34/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5546 - val_loss: 0.5617\n",
      "Epoch 35/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5452 - val_loss: 0.5663\n",
      "Epoch 36/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5498 - val_loss: 0.5790\n",
      "Epoch 37/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5404 - val_loss: 0.6871\n",
      "Epoch 38/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5387 - val_loss: 0.6510\n",
      "Epoch 39/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5528 - val_loss: 0.6505\n",
      "Epoch 40/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5480 - val_loss: 0.6209\n",
      "Epoch 41/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5626 - val_loss: 0.6601\n",
      "Epoch 42/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5514 - val_loss: 0.6981\n",
      "Epoch 43/1300\n",
      "233/233 [==============================] - 2s 8ms/step - loss: 0.5447 - val_loss: 0.5463\n",
      "Epoch 44/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5404 - val_loss: 0.6332\n",
      "Epoch 45/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5433 - val_loss: 0.5702\n",
      "Epoch 46/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5429 - val_loss: 0.7051\n",
      "Epoch 47/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5564 - val_loss: 0.5866\n",
      "Epoch 48/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5526 - val_loss: 0.5698\n",
      "Epoch 49/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5417 - val_loss: 0.7484\n",
      "Epoch 50/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5416 - val_loss: 1.0542\n",
      "Epoch 51/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5788 - val_loss: 0.8549\n",
      "Epoch 52/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5502 - val_loss: 0.5737\n",
      "Epoch 53/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5290 - val_loss: 0.8048\n",
      "Epoch 54/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5429 - val_loss: 0.5709\n",
      "Epoch 55/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5343 - val_loss: 0.6222\n",
      "Epoch 56/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5643 - val_loss: 0.5563\n",
      "Epoch 57/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5410 - val_loss: 0.5796\n",
      "Epoch 58/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5570 - val_loss: 0.5447\n",
      "Epoch 59/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5378 - val_loss: 0.5585\n",
      "Epoch 60/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.6193 - val_loss: 0.6634\n",
      "Epoch 61/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5566 - val_loss: 0.5614\n",
      "Epoch 62/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5413 - val_loss: 0.6037\n",
      "Epoch 63/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5443 - val_loss: 0.6288\n",
      "Epoch 64/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5553 - val_loss: 0.5490\n",
      "Epoch 65/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5418 - val_loss: 0.6121\n",
      "Epoch 66/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5330 - val_loss: 0.5469\n",
      "Epoch 67/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5597 - val_loss: 0.5882\n",
      "Epoch 68/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5378 - val_loss: 0.5717\n",
      "Epoch 69/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5621 - val_loss: 0.6502\n",
      "Epoch 70/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5353 - val_loss: 0.6370\n",
      "Epoch 71/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5342 - val_loss: 0.9902\n",
      "Epoch 72/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5612 - val_loss: 0.5756\n",
      "Epoch 73/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5459 - val_loss: 0.5634\n",
      "Epoch 74/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5474 - val_loss: 0.5840\n",
      "Epoch 75/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5353 - val_loss: 0.5612\n",
      "Epoch 76/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5597 - val_loss: 0.6286\n",
      "Epoch 77/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5419 - val_loss: 0.5662\n",
      "Epoch 78/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5489 - val_loss: 0.5531\n",
      "Epoch 79/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5310 - val_loss: 0.6738\n",
      "Epoch 80/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5480 - val_loss: 0.5546\n",
      "Epoch 81/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5322 - val_loss: 0.5756\n",
      "Epoch 82/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5294 - val_loss: 0.7330\n",
      "Epoch 83/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5647 - val_loss: 0.6160\n",
      "Epoch 84/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5659 - val_loss: 0.6391\n",
      "Epoch 85/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5345 - val_loss: 0.5653\n",
      "Epoch 86/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5335 - val_loss: 0.5973\n",
      "Epoch 87/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5482 - val_loss: 0.6016\n",
      "Epoch 88/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5431 - val_loss: 0.5773\n",
      "Epoch 89/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5451 - val_loss: 0.5836\n",
      "Epoch 90/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5505 - val_loss: 0.6147\n",
      "Epoch 91/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5553 - val_loss: 0.7164\n",
      "Epoch 92/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5511 - val_loss: 0.5946\n",
      "Epoch 93/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5460 - val_loss: 0.5572\n",
      "Epoch 94/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5377 - val_loss: 0.5486\n",
      "Epoch 95/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5400 - val_loss: 0.5963\n",
      "Epoch 96/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5374 - val_loss: 0.5737\n",
      "Epoch 97/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5498 - val_loss: 0.6334\n",
      "Epoch 98/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5267 - val_loss: 0.5410\n",
      "Epoch 99/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5408 - val_loss: 0.5488\n",
      "Epoch 100/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5366 - val_loss: 0.5519\n",
      "Epoch 101/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5457 - val_loss: 0.5857\n",
      "Epoch 102/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5534 - val_loss: 0.5671\n",
      "Epoch 103/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5664 - val_loss: 0.5492\n",
      "Epoch 104/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5341 - val_loss: 0.6462\n",
      "Epoch 105/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5376 - val_loss: 0.5675\n",
      "Epoch 106/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5436 - val_loss: 0.8230\n",
      "Epoch 107/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5419 - val_loss: 0.6762\n",
      "Epoch 108/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5387 - val_loss: 0.5574\n",
      "Epoch 109/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5519 - val_loss: 0.7086\n",
      "Epoch 110/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5376 - val_loss: 0.6429\n",
      "Epoch 111/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5412 - val_loss: 0.7520\n",
      "Epoch 112/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5476 - val_loss: 0.6578\n",
      "Epoch 113/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5535 - val_loss: 0.5524\n",
      "Epoch 114/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5254 - val_loss: 0.5479\n",
      "Epoch 115/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5676 - val_loss: 0.6695\n",
      "Epoch 116/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5283 - val_loss: 0.5510\n",
      "Epoch 117/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5387 - val_loss: 0.6414\n",
      "Epoch 118/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5397 - val_loss: 0.5422\n",
      "Epoch 119/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5222 - val_loss: 0.5650\n",
      "Epoch 120/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5465 - val_loss: 0.6114\n",
      "Epoch 121/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5338 - val_loss: 0.5888\n",
      "Epoch 122/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5474 - val_loss: 0.5516\n",
      "Epoch 123/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5292 - val_loss: 0.6922\n",
      "Epoch 124/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5321 - val_loss: 0.7070\n",
      "Epoch 125/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5470 - val_loss: 0.5707\n",
      "Epoch 126/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5415 - val_loss: 0.7864\n",
      "Epoch 127/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5359 - val_loss: 0.6061\n",
      "Epoch 128/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5248 - val_loss: 0.5873\n",
      "Epoch 129/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5355 - val_loss: 0.5561\n",
      "Epoch 130/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5389 - val_loss: 0.5483\n",
      "Epoch 131/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5356 - val_loss: 0.6799\n",
      "Epoch 132/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5309 - val_loss: 0.5549\n",
      "Epoch 133/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5337 - val_loss: 0.5574\n",
      "Epoch 134/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5331 - val_loss: 0.5802\n",
      "Epoch 135/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5300 - val_loss: 0.5649\n",
      "Epoch 136/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5383 - val_loss: 0.6441\n",
      "Epoch 137/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5449 - val_loss: 0.6635\n",
      "Epoch 138/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5306 - val_loss: 0.5547\n",
      "Epoch 139/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5309 - val_loss: 0.5639\n",
      "Epoch 140/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5418 - val_loss: 0.5900\n",
      "Epoch 141/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5508 - val_loss: 0.8053\n",
      "Epoch 142/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5363 - val_loss: 0.6005\n",
      "Epoch 143/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5389 - val_loss: 0.5584\n",
      "Epoch 144/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5532 - val_loss: 0.5570\n",
      "Epoch 145/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5413 - val_loss: 0.5784\n",
      "Epoch 146/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5217 - val_loss: 0.5658\n",
      "Epoch 147/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5232 - val_loss: 0.5651\n",
      "Epoch 148/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5512 - val_loss: 0.5697\n",
      "Epoch 149/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5585 - val_loss: 0.6580\n",
      "Epoch 150/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5403 - val_loss: 0.5490\n",
      "Epoch 151/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5531 - val_loss: 0.5641\n",
      "Epoch 152/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5471 - val_loss: 0.5432\n",
      "Epoch 153/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5324 - val_loss: 0.5488\n",
      "Epoch 154/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5352 - val_loss: 0.5452\n",
      "Epoch 155/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5292 - val_loss: 0.5452\n",
      "Epoch 156/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5327 - val_loss: 0.9098\n",
      "Epoch 157/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5315 - val_loss: 0.5505\n",
      "Epoch 158/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5192 - val_loss: 0.6625\n",
      "Epoch 159/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5538 - val_loss: 0.7423\n",
      "Epoch 160/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5565 - val_loss: 0.6466\n",
      "Epoch 161/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5138 - val_loss: 0.6336\n",
      "Epoch 162/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5329 - val_loss: 0.5614\n",
      "Epoch 163/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5328 - val_loss: 0.5499\n",
      "Epoch 164/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5295 - val_loss: 0.6421\n",
      "Epoch 165/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5331 - val_loss: 0.8221\n",
      "Epoch 166/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5421 - val_loss: 0.6623\n",
      "Epoch 167/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5497 - val_loss: 0.5962\n",
      "Epoch 168/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5592 - val_loss: 0.5458\n",
      "Epoch 169/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5238 - val_loss: 0.5580\n",
      "Epoch 170/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5280 - val_loss: 0.6059\n",
      "Epoch 171/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5490 - val_loss: 0.5741\n",
      "Epoch 172/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5441 - val_loss: 0.5443\n",
      "Epoch 173/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5389 - val_loss: 0.5677\n",
      "Epoch 174/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5272 - val_loss: 0.5585\n",
      "Epoch 175/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5362 - val_loss: 0.5534\n",
      "Epoch 176/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5406 - val_loss: 0.5890\n",
      "Epoch 177/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5487 - val_loss: 0.5477\n",
      "Epoch 178/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5460 - val_loss: 0.5956\n",
      "Epoch 179/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5420 - val_loss: 0.5554\n",
      "Epoch 180/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5264 - val_loss: 0.5597\n",
      "Epoch 181/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5235 - val_loss: 0.5651\n",
      "Epoch 182/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5310 - val_loss: 0.5433\n",
      "Epoch 183/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5449 - val_loss: 0.5623\n",
      "Epoch 184/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5318 - val_loss: 0.5520\n",
      "Epoch 185/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5404 - val_loss: 0.5520\n",
      "Epoch 186/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5311 - val_loss: 0.5695\n",
      "Epoch 187/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5307 - val_loss: 0.5501\n",
      "Epoch 188/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5339 - val_loss: 0.6287\n",
      "Epoch 189/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5286 - val_loss: 0.5781\n",
      "Epoch 190/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5310 - val_loss: 0.5508\n",
      "Epoch 191/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5213 - val_loss: 0.6633\n",
      "Epoch 192/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5513 - val_loss: 0.5442\n",
      "Epoch 193/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5444 - val_loss: 0.6232\n",
      "Epoch 194/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5212 - val_loss: 0.6126\n",
      "Epoch 195/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5215 - val_loss: 0.6045\n",
      "Epoch 196/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5243 - val_loss: 0.5714\n",
      "Epoch 197/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5327 - val_loss: 0.5526\n",
      "Epoch 198/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5250 - val_loss: 0.6300\n",
      "Epoch 199/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5437 - val_loss: 0.5436\n",
      "Epoch 200/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5171 - val_loss: 0.5759\n",
      "Epoch 201/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5460 - val_loss: 0.6620\n",
      "Epoch 202/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5316 - val_loss: 0.5732\n",
      "Epoch 203/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5254 - val_loss: 0.5933\n",
      "Epoch 204/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5627 - val_loss: 0.5658\n",
      "Epoch 205/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5351 - val_loss: 0.7069\n",
      "Epoch 206/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5270 - val_loss: 0.5442\n",
      "Epoch 207/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5382 - val_loss: 0.5583\n",
      "Epoch 208/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5504 - val_loss: 0.6033\n",
      "Epoch 209/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5335 - val_loss: 0.5416\n",
      "Epoch 210/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5444 - val_loss: 0.5573\n",
      "Epoch 211/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5358 - val_loss: 0.5665\n",
      "Epoch 212/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5250 - val_loss: 0.5630\n",
      "Epoch 213/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5357 - val_loss: 0.5452\n",
      "Epoch 214/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5344 - val_loss: 0.5411\n",
      "Epoch 215/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5319 - val_loss: 0.6874\n",
      "Epoch 216/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5291 - val_loss: 0.6652\n",
      "Epoch 217/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5300 - val_loss: 0.5782\n",
      "Epoch 218/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5341 - val_loss: 0.5793\n",
      "Epoch 219/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5147 - val_loss: 0.6643\n",
      "Epoch 220/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5367 - val_loss: 0.5466\n",
      "Epoch 221/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5245 - val_loss: 0.6188\n",
      "Epoch 222/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5376 - val_loss: 0.5753\n",
      "Epoch 223/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5494 - val_loss: 0.5550\n",
      "Epoch 224/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5389 - val_loss: 0.5677\n",
      "Epoch 225/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5239 - val_loss: 0.5417\n",
      "Epoch 226/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5122 - val_loss: 0.6430\n",
      "Epoch 227/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5383 - val_loss: 0.5438\n",
      "Epoch 228/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5224 - val_loss: 0.6493\n",
      "Epoch 229/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5575 - val_loss: 0.5448\n",
      "Epoch 230/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5289 - val_loss: 0.7462\n",
      "Epoch 231/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5317 - val_loss: 0.5608\n",
      "Epoch 232/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5228 - val_loss: 0.6279\n",
      "Epoch 233/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5335 - val_loss: 0.6084\n",
      "Epoch 234/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5419 - val_loss: 0.5443\n",
      "Epoch 235/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5145 - val_loss: 0.5443\n",
      "Epoch 236/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5304 - val_loss: 0.5791\n",
      "Epoch 237/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5276 - val_loss: 0.6573\n",
      "Epoch 238/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5228 - val_loss: 0.5628\n",
      "Epoch 239/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5473 - val_loss: 0.5833\n",
      "Epoch 240/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5364 - val_loss: 0.5701\n",
      "Epoch 241/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5323 - val_loss: 0.5819\n",
      "Epoch 242/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5245 - val_loss: 0.5555\n",
      "Epoch 243/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5166 - val_loss: 0.6192\n",
      "Epoch 244/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5207 - val_loss: 0.6934\n",
      "Epoch 245/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5523 - val_loss: 0.5382\n",
      "Epoch 246/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5227 - val_loss: 0.6101\n",
      "Epoch 247/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5480 - val_loss: 0.5665\n",
      "Epoch 248/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5307 - val_loss: 0.5487\n",
      "Epoch 249/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5324 - val_loss: 0.5640\n",
      "Epoch 250/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5274 - val_loss: 0.7248\n",
      "Epoch 251/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5366 - val_loss: 0.5810\n",
      "Epoch 252/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5350 - val_loss: 0.6697\n",
      "Epoch 253/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5290 - val_loss: 0.5452\n",
      "Epoch 254/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5343 - val_loss: 0.5494\n",
      "Epoch 255/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5363 - val_loss: 0.5816\n",
      "Epoch 256/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5619 - val_loss: 0.6548\n",
      "Epoch 257/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5353 - val_loss: 0.5646\n",
      "Epoch 258/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5300 - val_loss: 0.5495\n",
      "Epoch 259/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5423 - val_loss: 0.5525\n",
      "Epoch 260/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5163 - val_loss: 0.5916\n",
      "Epoch 261/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5235 - val_loss: 0.5529\n",
      "Epoch 262/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5276 - val_loss: 0.5474\n",
      "Epoch 263/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5280 - val_loss: 0.7473\n",
      "Epoch 264/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5318 - val_loss: 0.6377\n",
      "Epoch 265/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5430 - val_loss: 0.5866\n",
      "Epoch 266/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5459 - val_loss: 0.5408\n",
      "Epoch 267/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5408 - val_loss: 0.7555\n",
      "Epoch 268/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5571 - val_loss: 0.8779\n",
      "Epoch 269/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5810 - val_loss: 0.5742\n",
      "Epoch 270/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5298 - val_loss: 0.7117\n",
      "Epoch 271/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5263 - val_loss: 0.7416\n",
      "Epoch 272/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5341 - val_loss: 0.5688\n",
      "Epoch 273/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5287 - val_loss: 0.5511\n",
      "Epoch 274/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5279 - val_loss: 0.5465\n",
      "Epoch 275/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5210 - val_loss: 0.5838\n",
      "Epoch 276/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5333 - val_loss: 0.5533\n",
      "Epoch 277/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5395 - val_loss: 0.5781\n",
      "Epoch 278/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5424 - val_loss: 0.6506\n",
      "Epoch 279/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5410 - val_loss: 0.5640\n",
      "Epoch 280/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5382 - val_loss: 0.5759\n",
      "Epoch 281/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5639 - val_loss: 0.5757\n",
      "Epoch 282/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5292 - val_loss: 0.6717\n",
      "Epoch 283/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5312 - val_loss: 0.7623\n",
      "Epoch 284/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5382 - val_loss: 0.5462\n",
      "Epoch 285/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5354 - val_loss: 0.5500\n",
      "Epoch 286/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5269 - val_loss: 0.6943\n",
      "Epoch 287/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5446 - val_loss: 0.5618\n",
      "Epoch 288/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5436 - val_loss: 0.5899\n",
      "Epoch 289/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5280 - val_loss: 0.6721\n",
      "Epoch 290/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5282 - val_loss: 0.5632\n",
      "Epoch 291/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5223 - val_loss: 0.5523\n",
      "Epoch 292/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5268 - val_loss: 0.5804\n",
      "Epoch 293/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5215 - val_loss: 0.6059\n",
      "Epoch 294/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5340 - val_loss: 0.5551\n",
      "Epoch 295/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5236 - val_loss: 0.5761\n",
      "Epoch 296/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5349 - val_loss: 0.6963\n",
      "Epoch 297/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5301 - val_loss: 0.5433\n",
      "Epoch 298/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5207 - val_loss: 0.5458\n",
      "Epoch 299/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5455 - val_loss: 0.5572\n",
      "Epoch 300/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5252 - val_loss: 0.5613\n",
      "Epoch 301/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5143 - val_loss: 0.6926\n",
      "Epoch 302/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5252 - val_loss: 0.5611\n",
      "Epoch 303/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5167 - val_loss: 0.5565\n",
      "Epoch 304/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5284 - val_loss: 0.5666\n",
      "Epoch 305/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5328 - val_loss: 0.6525\n",
      "Epoch 306/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5236 - val_loss: 0.5584\n",
      "Epoch 307/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5314 - val_loss: 0.5565\n",
      "Epoch 308/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5104 - val_loss: 0.5922\n",
      "Epoch 309/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5302 - val_loss: 0.5612\n",
      "Epoch 310/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5156 - val_loss: 0.5702\n",
      "Epoch 311/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5193 - val_loss: 0.5562\n",
      "Epoch 312/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5241 - val_loss: 0.5894\n",
      "Epoch 313/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5384 - val_loss: 0.7318\n",
      "Epoch 314/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5421 - val_loss: 0.5430\n",
      "Epoch 315/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5319 - val_loss: 0.5645\n",
      "Epoch 316/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5240 - val_loss: 0.6369\n",
      "Epoch 317/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5572 - val_loss: 0.5580\n",
      "Epoch 318/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5275 - val_loss: 0.5679\n",
      "Epoch 319/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5163 - val_loss: 0.5497\n",
      "Epoch 320/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5364 - val_loss: 0.5881\n",
      "Epoch 321/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5238 - val_loss: 0.5656\n",
      "Epoch 322/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5259 - val_loss: 0.5618\n",
      "Epoch 323/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5135 - val_loss: 0.5883\n",
      "Epoch 324/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5704 - val_loss: 0.5779\n",
      "Epoch 325/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5222 - val_loss: 0.6163\n",
      "Epoch 326/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5244 - val_loss: 0.5947\n",
      "Epoch 327/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5320 - val_loss: 0.6093\n",
      "Epoch 328/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5270 - val_loss: 0.5481\n",
      "Epoch 329/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5269 - val_loss: 0.5839\n",
      "Epoch 330/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5278 - val_loss: 0.5756\n",
      "Epoch 331/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5293 - val_loss: 0.5701\n",
      "Epoch 332/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5274 - val_loss: 0.9011\n",
      "Epoch 333/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5224 - val_loss: 0.5516\n",
      "Epoch 334/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5264 - val_loss: 0.5521\n",
      "Epoch 335/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5262 - val_loss: 0.6402\n",
      "Epoch 336/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5289 - val_loss: 0.5565\n",
      "Epoch 337/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5173 - val_loss: 0.6061\n",
      "Epoch 338/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5208 - val_loss: 0.6575\n",
      "Epoch 339/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5312 - val_loss: 0.5469\n",
      "Epoch 340/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5582 - val_loss: 0.5769\n",
      "Epoch 341/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5303 - val_loss: 0.7028\n",
      "Epoch 342/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5470 - val_loss: 0.5576\n",
      "Epoch 343/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5195 - val_loss: 0.5553\n",
      "Epoch 344/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5228 - val_loss: 0.6010\n",
      "Epoch 345/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5215 - val_loss: 0.6762\n",
      "Epoch 346/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5174 - val_loss: 0.5741\n",
      "Epoch 347/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5151 - val_loss: 0.5533\n",
      "Epoch 348/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5185 - val_loss: 0.5500\n",
      "Epoch 349/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5499 - val_loss: 0.7500\n",
      "Epoch 350/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5191 - val_loss: 0.5487\n",
      "Epoch 351/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5107 - val_loss: 0.5533\n",
      "Epoch 352/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5218 - val_loss: 0.5693\n",
      "Epoch 353/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5335 - val_loss: 0.5550\n",
      "Epoch 354/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5130 - val_loss: 0.5997\n",
      "Epoch 355/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5211 - val_loss: 0.5599\n",
      "Epoch 356/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5219 - val_loss: 0.5507\n",
      "Epoch 357/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5424 - val_loss: 0.5899\n",
      "Epoch 358/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5198 - val_loss: 0.5506\n",
      "Epoch 359/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5157 - val_loss: 0.5535\n",
      "Epoch 360/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5278 - val_loss: 0.5521\n",
      "Epoch 361/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5401 - val_loss: 0.6468\n",
      "Epoch 362/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5239 - val_loss: 0.6226\n",
      "Epoch 363/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5270 - val_loss: 0.6762\n",
      "Epoch 364/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5229 - val_loss: 0.5633\n",
      "Epoch 365/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5139 - val_loss: 0.5502\n",
      "Epoch 366/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5117 - val_loss: 0.8977\n",
      "Epoch 367/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5282 - val_loss: 0.5604\n",
      "Epoch 368/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5116 - val_loss: 0.5584\n",
      "Epoch 369/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5203 - val_loss: 0.5948\n",
      "Epoch 370/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5603 - val_loss: 0.6539\n",
      "Epoch 371/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5296 - val_loss: 0.6194\n",
      "Epoch 372/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5185 - val_loss: 0.5499\n",
      "Epoch 373/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5313 - val_loss: 0.5522\n",
      "Epoch 374/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5135 - val_loss: 0.5892\n",
      "Epoch 375/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5508 - val_loss: 0.5518\n",
      "Epoch 376/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5306 - val_loss: 0.7415\n",
      "Epoch 377/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5298 - val_loss: 0.5477\n",
      "Epoch 378/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5450 - val_loss: 0.5609\n",
      "Epoch 379/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5464 - val_loss: 0.8648\n",
      "Epoch 380/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5205 - val_loss: 0.5551\n",
      "Epoch 381/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5124 - val_loss: 1.1119\n",
      "Epoch 382/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5367 - val_loss: 0.6224\n",
      "Epoch 383/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5180 - val_loss: 0.6163\n",
      "Epoch 384/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5398 - val_loss: 0.5852\n",
      "Epoch 385/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5448 - val_loss: 0.5526\n",
      "Epoch 386/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5129 - val_loss: 0.5821\n",
      "Epoch 387/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5119 - val_loss: 0.7336\n",
      "Epoch 388/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5142 - val_loss: 0.6020\n",
      "Epoch 389/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5213 - val_loss: 0.6309\n",
      "Epoch 390/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5148 - val_loss: 0.5575\n",
      "Epoch 391/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5128 - val_loss: 0.5519\n",
      "Epoch 392/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5157 - val_loss: 0.5753\n",
      "Epoch 393/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5223 - val_loss: 0.6726\n",
      "Epoch 394/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5248 - val_loss: 0.6115\n",
      "Epoch 395/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5314 - val_loss: 0.5803\n",
      "Epoch 396/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5363 - val_loss: 0.5621\n",
      "Epoch 397/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5621 - val_loss: 0.8437\n",
      "Epoch 398/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5556 - val_loss: 0.5533\n",
      "Epoch 399/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5242 - val_loss: 0.5799\n",
      "Epoch 400/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5145 - val_loss: 0.5458\n",
      "Epoch 401/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5125 - val_loss: 0.5820\n",
      "Epoch 402/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5207 - val_loss: 0.7105\n",
      "Epoch 403/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5195 - val_loss: 0.5679\n",
      "Epoch 404/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5301 - val_loss: 0.5738\n",
      "Epoch 405/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5441 - val_loss: 0.6483\n",
      "Epoch 406/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5208 - val_loss: 0.6126\n",
      "Epoch 407/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5247 - val_loss: 0.5529\n",
      "Epoch 408/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5187 - val_loss: 0.5483\n",
      "Epoch 409/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5212 - val_loss: 0.5493\n",
      "Epoch 410/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5181 - val_loss: 0.7271\n",
      "Epoch 411/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5200 - val_loss: 0.5674\n",
      "Epoch 412/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5255 - val_loss: 0.5505\n",
      "Epoch 413/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5260 - val_loss: 0.5559\n",
      "Epoch 414/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5123 - val_loss: 0.5453\n",
      "Epoch 415/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5301 - val_loss: 0.6986\n",
      "Epoch 416/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5212 - val_loss: 0.5591\n",
      "Epoch 417/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5105 - val_loss: 0.5583\n",
      "Epoch 418/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5277 - val_loss: 0.5808\n",
      "Epoch 419/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5211 - val_loss: 0.6486\n",
      "Epoch 420/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5335 - val_loss: 0.5583\n",
      "Epoch 421/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5207 - val_loss: 0.5478\n",
      "Epoch 422/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5225 - val_loss: 0.5530\n",
      "Epoch 423/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5409 - val_loss: 0.5705\n",
      "Epoch 424/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5242 - val_loss: 0.5670\n",
      "Epoch 425/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5165 - val_loss: 0.5602\n",
      "Epoch 426/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5215 - val_loss: 0.5594\n",
      "Epoch 427/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5242 - val_loss: 0.5941\n",
      "Epoch 428/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5164 - val_loss: 0.5811\n",
      "Epoch 429/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5301 - val_loss: 0.5805\n",
      "Epoch 430/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5176 - val_loss: 0.5603\n",
      "Epoch 431/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5148 - val_loss: 0.5947\n",
      "Epoch 432/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5230 - val_loss: 0.5912\n",
      "Epoch 433/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5458 - val_loss: 0.6180\n",
      "Epoch 434/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5166 - val_loss: 0.5487\n",
      "Epoch 435/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5242 - val_loss: 0.6757\n",
      "Epoch 436/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5218 - val_loss: 0.6659\n",
      "Epoch 437/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5307 - val_loss: 0.7235\n",
      "Epoch 438/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5161 - val_loss: 0.6459\n",
      "Epoch 439/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5320 - val_loss: 0.5521\n",
      "Epoch 440/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5211 - val_loss: 0.5475\n",
      "Epoch 441/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5163 - val_loss: 0.5819\n",
      "Epoch 442/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5170 - val_loss: 0.5643\n",
      "Epoch 443/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5155 - val_loss: 0.5524\n",
      "Epoch 444/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5087 - val_loss: 0.5944\n",
      "Epoch 445/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5106 - val_loss: 0.5461\n",
      "Epoch 446/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5097 - val_loss: 0.6001\n",
      "Epoch 447/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5342 - val_loss: 0.5537\n",
      "Epoch 448/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5392 - val_loss: 0.6777\n",
      "Epoch 449/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5354 - val_loss: 0.7661\n",
      "Epoch 450/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5463 - val_loss: 0.6291\n",
      "Epoch 451/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5185 - val_loss: 0.8522\n",
      "Epoch 452/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5208 - val_loss: 0.5585\n",
      "Epoch 453/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5288 - val_loss: 0.5555\n",
      "Epoch 454/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5091 - val_loss: 0.5589\n",
      "Epoch 455/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5031 - val_loss: 0.5450\n",
      "Epoch 456/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5163 - val_loss: 0.6477\n",
      "Epoch 457/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5121 - val_loss: 0.6126\n",
      "Epoch 458/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5144 - val_loss: 0.6291\n",
      "Epoch 459/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5236 - val_loss: 0.5569\n",
      "Epoch 460/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5122 - val_loss: 0.5597\n",
      "Epoch 461/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5139 - val_loss: 0.5459\n",
      "Epoch 462/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5116 - val_loss: 0.5499\n",
      "Epoch 463/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5180 - val_loss: 0.7258\n",
      "Epoch 464/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5181 - val_loss: 0.5878\n",
      "Epoch 465/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5079 - val_loss: 0.5539\n",
      "Epoch 466/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5173 - val_loss: 0.6245\n",
      "Epoch 467/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5143 - val_loss: 0.5400\n",
      "Epoch 468/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5197 - val_loss: 0.7014\n",
      "Epoch 469/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5297 - val_loss: 0.5774\n",
      "Epoch 470/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5123 - val_loss: 0.5726\n",
      "Epoch 471/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5299 - val_loss: 0.5658\n",
      "Epoch 472/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5229 - val_loss: 0.6044\n",
      "Epoch 473/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5192 - val_loss: 0.6492\n",
      "Epoch 474/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5158 - val_loss: 0.5701\n",
      "Epoch 475/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5228 - val_loss: 0.5703\n",
      "Epoch 476/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5107 - val_loss: 0.5416\n",
      "Epoch 477/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5188 - val_loss: 0.5465\n",
      "Epoch 478/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5127 - val_loss: 0.5364\n",
      "Epoch 479/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5149 - val_loss: 0.5726\n",
      "Epoch 480/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5363 - val_loss: 0.6624\n",
      "Epoch 481/1300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.5233 - val_loss: 0.6315\n",
      "Epoch 482/1300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.5124 - val_loss: 0.5846\n",
      "Epoch 483/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5078 - val_loss: 0.5867\n",
      "Epoch 484/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5157 - val_loss: 0.5456\n",
      "Epoch 485/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5088 - val_loss: 0.5387\n",
      "Epoch 486/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5123 - val_loss: 0.5528\n",
      "Epoch 487/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5288 - val_loss: 0.5377\n",
      "Epoch 488/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5128 - val_loss: 0.7322\n",
      "Epoch 489/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5286 - val_loss: 0.6045\n",
      "Epoch 490/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5180 - val_loss: 0.5626\n",
      "Epoch 491/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5124 - val_loss: 0.5725\n",
      "Epoch 492/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5103 - val_loss: 0.5457\n",
      "Epoch 493/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5084 - val_loss: 0.5664\n",
      "Epoch 494/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5236 - val_loss: 0.5446\n",
      "Epoch 495/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5168 - val_loss: 0.6374\n",
      "Epoch 496/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5207 - val_loss: 0.7022\n",
      "Epoch 497/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5088 - val_loss: 0.7148\n",
      "Epoch 498/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5111 - val_loss: 0.5483\n",
      "Epoch 499/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5206 - val_loss: 0.5382\n",
      "Epoch 500/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5204 - val_loss: 0.6331\n",
      "Epoch 501/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5143 - val_loss: 0.5705\n",
      "Epoch 502/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5120 - val_loss: 0.6090\n",
      "Epoch 503/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5282 - val_loss: 0.6280\n",
      "Epoch 504/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5116 - val_loss: 0.5732\n",
      "Epoch 505/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5083 - val_loss: 0.5465\n",
      "Epoch 506/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5034 - val_loss: 0.5500\n",
      "Epoch 507/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5167 - val_loss: 0.5372\n",
      "Epoch 508/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5271 - val_loss: 0.5744\n",
      "Epoch 509/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5210 - val_loss: 0.5957\n",
      "Epoch 510/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5200 - val_loss: 0.5420\n",
      "Epoch 511/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5054 - val_loss: 0.5390\n",
      "Epoch 512/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5196 - val_loss: 0.5407\n",
      "Epoch 513/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5211 - val_loss: 0.5399\n",
      "Epoch 514/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5137 - val_loss: 0.5998\n",
      "Epoch 515/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5151 - val_loss: 0.5753\n",
      "Epoch 516/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5034 - val_loss: 0.5482\n",
      "Epoch 517/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5059 - val_loss: 0.6023\n",
      "Epoch 518/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5151 - val_loss: 0.8809\n",
      "Epoch 519/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5168 - val_loss: 0.5396\n",
      "Epoch 520/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5105 - val_loss: 0.5372\n",
      "Epoch 521/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5145 - val_loss: 0.5897\n",
      "Epoch 522/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5256 - val_loss: 0.5616\n",
      "Epoch 523/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5127 - val_loss: 0.5872\n",
      "Epoch 524/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5226 - val_loss: 0.5710\n",
      "Epoch 525/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5123 - val_loss: 0.5669\n",
      "Epoch 526/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5240 - val_loss: 0.8253\n",
      "Epoch 527/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5161 - val_loss: 0.5778\n",
      "Epoch 528/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5063 - val_loss: 0.5357\n",
      "Epoch 529/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5082 - val_loss: 0.5403\n",
      "Epoch 530/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5043 - val_loss: 0.5412\n",
      "Epoch 531/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5067 - val_loss: 0.5401\n",
      "Epoch 532/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5093 - val_loss: 0.5451\n",
      "Epoch 533/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5098 - val_loss: 0.5511\n",
      "Epoch 534/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5185 - val_loss: 0.5430\n",
      "Epoch 535/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5096 - val_loss: 0.6876\n",
      "Epoch 536/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5116 - val_loss: 0.6275\n",
      "Epoch 537/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5199 - val_loss: 0.5877\n",
      "Epoch 538/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5210 - val_loss: 0.5659\n",
      "Epoch 539/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5151 - val_loss: 0.5713\n",
      "Epoch 540/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5155 - val_loss: 0.5689\n",
      "Epoch 541/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5184 - val_loss: 0.5427\n",
      "Epoch 542/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5138 - val_loss: 0.6057\n",
      "Epoch 543/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5035 - val_loss: 0.6081\n",
      "Epoch 544/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5083 - val_loss: 0.5356\n",
      "Epoch 545/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5143 - val_loss: 0.5401\n",
      "Epoch 546/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5206 - val_loss: 0.5464\n",
      "Epoch 547/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5117 - val_loss: 0.6234\n",
      "Epoch 548/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5119 - val_loss: 0.5787\n",
      "Epoch 549/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5217 - val_loss: 0.6335\n",
      "Epoch 550/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5132 - val_loss: 0.6286\n",
      "Epoch 551/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5210 - val_loss: 0.5366\n",
      "Epoch 552/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5074 - val_loss: 0.5562\n",
      "Epoch 553/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5114 - val_loss: 0.5676\n",
      "Epoch 554/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5142 - val_loss: 0.6878\n",
      "Epoch 555/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5139 - val_loss: 0.5421\n",
      "Epoch 556/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5131 - val_loss: 0.6041\n",
      "Epoch 557/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5150 - val_loss: 0.5391\n",
      "Epoch 558/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5179 - val_loss: 0.5556\n",
      "Epoch 559/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5081 - val_loss: 0.5573\n",
      "Epoch 560/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5161 - val_loss: 0.5760\n",
      "Epoch 561/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5231 - val_loss: 0.5780\n",
      "Epoch 562/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5110 - val_loss: 0.6233\n",
      "Epoch 563/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5068 - val_loss: 0.5616\n",
      "Epoch 564/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5125 - val_loss: 0.7604\n",
      "Epoch 565/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5316 - val_loss: 0.5758\n",
      "Epoch 566/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5040 - val_loss: 0.5580\n",
      "Epoch 567/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5167 - val_loss: 0.5470\n",
      "Epoch 568/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5043 - val_loss: 0.7799\n",
      "Epoch 569/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5194 - val_loss: 0.5972\n",
      "Epoch 570/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5259 - val_loss: 0.5501\n",
      "Epoch 571/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5239 - val_loss: 0.5419\n",
      "Epoch 572/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5064 - val_loss: 0.5595\n",
      "Epoch 573/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5120 - val_loss: 0.5589\n",
      "Epoch 574/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5037 - val_loss: 0.5439\n",
      "Epoch 575/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5100 - val_loss: 0.6051\n",
      "Epoch 576/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5071 - val_loss: 0.5407\n",
      "Epoch 577/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5133 - val_loss: 0.5876\n",
      "Epoch 578/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5133 - val_loss: 0.5530\n",
      "Epoch 579/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5096 - val_loss: 0.5536\n",
      "Epoch 580/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5074 - val_loss: 0.6001\n",
      "Epoch 581/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5167 - val_loss: 0.9278\n",
      "Epoch 582/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5161 - val_loss: 0.5377\n",
      "Epoch 583/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5085 - val_loss: 0.5538\n",
      "Epoch 584/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5082 - val_loss: 0.6482\n",
      "Epoch 585/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5077 - val_loss: 0.6022\n",
      "Epoch 586/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5203 - val_loss: 0.7468\n",
      "Epoch 587/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5167 - val_loss: 0.6451\n",
      "Epoch 588/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5151 - val_loss: 0.5786\n",
      "Epoch 589/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5041 - val_loss: 0.6122\n",
      "Epoch 590/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5122 - val_loss: 0.5513\n",
      "Epoch 591/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5051 - val_loss: 0.6199\n",
      "Epoch 592/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5100 - val_loss: 0.5608\n",
      "Epoch 593/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5163 - val_loss: 0.6529\n",
      "Epoch 594/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5179 - val_loss: 0.5718\n",
      "Epoch 595/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5136 - val_loss: 0.5597\n",
      "Epoch 596/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5217 - val_loss: 0.5520\n",
      "Epoch 597/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5079 - val_loss: 0.5733\n",
      "Epoch 598/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5006 - val_loss: 0.5378\n",
      "Epoch 599/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5099 - val_loss: 0.6191\n",
      "Epoch 600/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5130 - val_loss: 0.5542\n",
      "Epoch 601/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5103 - val_loss: 0.6947\n",
      "Epoch 602/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5179 - val_loss: 0.5904\n",
      "Epoch 603/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5039 - val_loss: 0.6212\n",
      "Epoch 604/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5080 - val_loss: 0.5503\n",
      "Epoch 605/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5089 - val_loss: 0.5553\n",
      "Epoch 606/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5122 - val_loss: 0.5905\n",
      "Epoch 607/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5062 - val_loss: 0.6347\n",
      "Epoch 608/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5157 - val_loss: 0.5954\n",
      "Epoch 609/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5167 - val_loss: 0.5680\n",
      "Epoch 610/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5106 - val_loss: 0.5468\n",
      "Epoch 611/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5092 - val_loss: 0.5937\n",
      "Epoch 612/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5134 - val_loss: 0.5529\n",
      "Epoch 613/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5103 - val_loss: 0.5651\n",
      "Epoch 614/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5150 - val_loss: 0.5760\n",
      "Epoch 615/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5100 - val_loss: 0.5599\n",
      "Epoch 616/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5101 - val_loss: 0.5497\n",
      "Epoch 617/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5070 - val_loss: 0.5957\n",
      "Epoch 618/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5140 - val_loss: 0.5677\n",
      "Epoch 619/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5031 - val_loss: 0.5440\n",
      "Epoch 620/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5071 - val_loss: 0.6613\n",
      "Epoch 621/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5105 - val_loss: 1.1333\n",
      "Epoch 622/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5321 - val_loss: 0.7289\n",
      "Epoch 623/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5129 - val_loss: 0.5539\n",
      "Epoch 624/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5061 - val_loss: 0.5405\n",
      "Epoch 625/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5281 - val_loss: 0.5737\n",
      "Epoch 626/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5220 - val_loss: 0.5391\n",
      "Epoch 627/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5194 - val_loss: 0.5795\n",
      "Epoch 628/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5113 - val_loss: 0.5413\n",
      "Epoch 629/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5141 - val_loss: 0.6056\n",
      "Epoch 630/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5128 - val_loss: 0.5435\n",
      "Epoch 631/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5201 - val_loss: 0.5468\n",
      "Epoch 632/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5095 - val_loss: 0.5976\n",
      "Epoch 633/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5157 - val_loss: 0.6596\n",
      "Epoch 634/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5114 - val_loss: 0.5718\n",
      "Epoch 635/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5204 - val_loss: 0.5514\n",
      "Epoch 636/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5145 - val_loss: 0.5528\n",
      "Epoch 637/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5154 - val_loss: 0.5472\n",
      "Epoch 638/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5164 - val_loss: 0.6480\n",
      "Epoch 639/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5114 - val_loss: 0.5667\n",
      "Epoch 640/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5229 - val_loss: 0.5433\n",
      "Epoch 641/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5056 - val_loss: 0.6887\n",
      "Epoch 642/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5320 - val_loss: 0.5396\n",
      "Epoch 643/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5041 - val_loss: 0.5427\n",
      "Epoch 644/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5111 - val_loss: 0.5395\n",
      "Epoch 645/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5059 - val_loss: 0.5737\n",
      "Epoch 646/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5136 - val_loss: 0.5344\n",
      "Epoch 647/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5060 - val_loss: 0.5521\n",
      "Epoch 648/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5030 - val_loss: 0.6226\n",
      "Epoch 649/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5079 - val_loss: 0.7434\n",
      "Epoch 650/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5135 - val_loss: 0.5775\n",
      "Epoch 651/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5099 - val_loss: 0.6678\n",
      "Epoch 652/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5261 - val_loss: 0.5519\n",
      "Epoch 653/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5035 - val_loss: 0.5577\n",
      "Epoch 654/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5077 - val_loss: 0.8766\n",
      "Epoch 655/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5189 - val_loss: 0.6630\n",
      "Epoch 656/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5220 - val_loss: 0.5680\n",
      "Epoch 657/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5024 - val_loss: 0.5454\n",
      "Epoch 658/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5037 - val_loss: 0.5930\n",
      "Epoch 659/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5066 - val_loss: 0.5401\n",
      "Epoch 660/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5105 - val_loss: 0.5396\n",
      "Epoch 661/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5062 - val_loss: 0.5350\n",
      "Epoch 662/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5133 - val_loss: 0.6351\n",
      "Epoch 663/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5112 - val_loss: 0.5432\n",
      "Epoch 664/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5092 - val_loss: 0.7507\n",
      "Epoch 665/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5167 - val_loss: 0.6093\n",
      "Epoch 666/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5230 - val_loss: 0.5480\n",
      "Epoch 667/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5061 - val_loss: 0.5549\n",
      "Epoch 668/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5095 - val_loss: 0.5888\n",
      "Epoch 669/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5118 - val_loss: 0.6035\n",
      "Epoch 670/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5052 - val_loss: 0.6359\n",
      "Epoch 671/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5090 - val_loss: 0.5583\n",
      "Epoch 672/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5123 - val_loss: 0.6243\n",
      "Epoch 673/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5090 - val_loss: 0.7292\n",
      "Epoch 674/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5158 - val_loss: 0.5969\n",
      "Epoch 675/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5087 - val_loss: 0.5346\n",
      "Epoch 676/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5052 - val_loss: 0.5715\n",
      "Epoch 677/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5224 - val_loss: 0.5380\n",
      "Epoch 678/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5142 - val_loss: 0.5937\n",
      "Epoch 679/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5147 - val_loss: 0.5415\n",
      "Epoch 680/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5097 - val_loss: 0.5425\n",
      "Epoch 681/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5041 - val_loss: 0.5378\n",
      "Epoch 682/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5152 - val_loss: 0.5658\n",
      "Epoch 683/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5052 - val_loss: 0.5385\n",
      "Epoch 684/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4994 - val_loss: 0.5405\n",
      "Epoch 685/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5085 - val_loss: 0.5551\n",
      "Epoch 686/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5223 - val_loss: 0.6333\n",
      "Epoch 687/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5190 - val_loss: 0.5735\n",
      "Epoch 688/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5100 - val_loss: 0.5439\n",
      "Epoch 689/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5026 - val_loss: 0.5396\n",
      "Epoch 690/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5090 - val_loss: 0.5436\n",
      "Epoch 691/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5016 - val_loss: 0.5414\n",
      "Epoch 692/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5081 - val_loss: 0.5449\n",
      "Epoch 693/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5081 - val_loss: 0.5515\n",
      "Epoch 694/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5135 - val_loss: 0.5494\n",
      "Epoch 695/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5067 - val_loss: 0.5693\n",
      "Epoch 696/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5044 - val_loss: 0.5516\n",
      "Epoch 697/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5043 - val_loss: 0.5382\n",
      "Epoch 698/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5067 - val_loss: 0.7589\n",
      "Epoch 699/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5110 - val_loss: 0.5911\n",
      "Epoch 700/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5046 - val_loss: 0.5668\n",
      "Epoch 701/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5375 - val_loss: 0.6734\n",
      "Epoch 702/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5115 - val_loss: 0.6184\n",
      "Epoch 703/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5061 - val_loss: 0.5818\n",
      "Epoch 704/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5050 - val_loss: 0.5547\n",
      "Epoch 705/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5142 - val_loss: 0.5385\n",
      "Epoch 706/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5140 - val_loss: 0.5608\n",
      "Epoch 707/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5059 - val_loss: 0.5705\n",
      "Epoch 708/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5058 - val_loss: 0.6926\n",
      "Epoch 709/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5119 - val_loss: 0.5381\n",
      "Epoch 710/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5088 - val_loss: 0.5430\n",
      "Epoch 711/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5112 - val_loss: 0.5399\n",
      "Epoch 712/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5055 - val_loss: 0.5368\n",
      "Epoch 713/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5056 - val_loss: 0.5348\n",
      "Epoch 714/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5054 - val_loss: 0.5492\n",
      "Epoch 715/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5199 - val_loss: 0.6742\n",
      "Epoch 716/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5079 - val_loss: 0.5686\n",
      "Epoch 717/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5102 - val_loss: 0.5447\n",
      "Epoch 718/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5063 - val_loss: 0.5615\n",
      "Epoch 719/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5160 - val_loss: 0.6583\n",
      "Epoch 720/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5180 - val_loss: 0.5540\n",
      "Epoch 721/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5066 - val_loss: 0.5566\n",
      "Epoch 722/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5073 - val_loss: 0.8230\n",
      "Epoch 723/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5212 - val_loss: 0.5424\n",
      "Epoch 724/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5101 - val_loss: 0.5411\n",
      "Epoch 725/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5061 - val_loss: 0.5353\n",
      "Epoch 726/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5052 - val_loss: 0.6903\n",
      "Epoch 727/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5135 - val_loss: 0.5646\n",
      "Epoch 728/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5078 - val_loss: 0.6072\n",
      "Epoch 729/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5126 - val_loss: 0.5376\n",
      "Epoch 730/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5003 - val_loss: 0.5452\n",
      "Epoch 731/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5012 - val_loss: 0.5354\n",
      "Epoch 732/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5047 - val_loss: 0.5542\n",
      "Epoch 733/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5163 - val_loss: 0.5410\n",
      "Epoch 734/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5103 - val_loss: 0.5989\n",
      "Epoch 735/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5131 - val_loss: 0.5600\n",
      "Epoch 736/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5071 - val_loss: 0.7888\n",
      "Epoch 737/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5163 - val_loss: 0.5418\n",
      "Epoch 738/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5055 - val_loss: 0.5422\n",
      "Epoch 739/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5095 - val_loss: 0.5428\n",
      "Epoch 740/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5038 - val_loss: 0.5978\n",
      "Epoch 741/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5063 - val_loss: 0.5372\n",
      "Epoch 742/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5065 - val_loss: 0.5722\n",
      "Epoch 743/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5065 - val_loss: 0.5390\n",
      "Epoch 744/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5034 - val_loss: 0.6389\n",
      "Epoch 745/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5078 - val_loss: 0.5396\n",
      "Epoch 746/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5179 - val_loss: 0.5398\n",
      "Epoch 747/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5070 - val_loss: 0.5460\n",
      "Epoch 748/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5053 - val_loss: 0.6149\n",
      "Epoch 749/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5034 - val_loss: 0.6150\n",
      "Epoch 750/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5012 - val_loss: 0.6281\n",
      "Epoch 751/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5077 - val_loss: 0.5637\n",
      "Epoch 752/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5152 - val_loss: 0.5352\n",
      "Epoch 753/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5020 - val_loss: 0.5368\n",
      "Epoch 754/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5049 - val_loss: 0.5546\n",
      "Epoch 755/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5146 - val_loss: 0.7100\n",
      "Epoch 756/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5158 - val_loss: 0.5405\n",
      "Epoch 757/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5002 - val_loss: 0.5345\n",
      "Epoch 758/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5038 - val_loss: 0.5663\n",
      "Epoch 759/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5106 - val_loss: 0.5343\n",
      "Epoch 760/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5102 - val_loss: 0.7019\n",
      "Epoch 761/1300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.5072 - val_loss: 0.6505\n",
      "Epoch 762/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5134 - val_loss: 0.5467\n",
      "Epoch 763/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5158 - val_loss: 0.5556\n",
      "Epoch 764/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5035 - val_loss: 0.6969\n",
      "Epoch 765/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5049 - val_loss: 0.6064\n",
      "Epoch 766/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5071 - val_loss: 0.5400\n",
      "Epoch 767/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5037 - val_loss: 0.5327\n",
      "Epoch 768/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5109 - val_loss: 0.6581\n",
      "Epoch 769/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5130 - val_loss: 0.5584\n",
      "Epoch 770/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5034 - val_loss: 0.5368\n",
      "Epoch 771/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5024 - val_loss: 0.5616\n",
      "Epoch 772/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5059 - val_loss: 0.5428\n",
      "Epoch 773/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5192 - val_loss: 0.5517\n",
      "Epoch 774/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5065 - val_loss: 0.5567\n",
      "Epoch 775/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5061 - val_loss: 0.5370\n",
      "Epoch 776/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5145 - val_loss: 0.5352\n",
      "Epoch 777/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5122 - val_loss: 0.5439\n",
      "Epoch 778/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5113 - val_loss: 0.5415\n",
      "Epoch 779/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5099 - val_loss: 0.5752\n",
      "Epoch 780/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5039 - val_loss: 0.5578\n",
      "Epoch 781/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5064 - val_loss: 0.5375\n",
      "Epoch 782/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5149 - val_loss: 0.5572\n",
      "Epoch 783/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5003 - val_loss: 0.5398\n",
      "Epoch 784/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5041 - val_loss: 0.6346\n",
      "Epoch 785/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5104 - val_loss: 0.5324\n",
      "Epoch 786/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5105 - val_loss: 0.5494\n",
      "Epoch 787/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5124 - val_loss: 0.6119\n",
      "Epoch 788/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5168 - val_loss: 0.5396\n",
      "Epoch 789/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5119 - val_loss: 0.5317\n",
      "Epoch 790/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4979 - val_loss: 0.5929\n",
      "Epoch 791/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5006 - val_loss: 0.5941\n",
      "Epoch 792/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5110 - val_loss: 0.5390\n",
      "Epoch 793/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5095 - val_loss: 0.6415\n",
      "Epoch 794/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5214 - val_loss: 0.5339\n",
      "Epoch 795/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4982 - val_loss: 0.5673\n",
      "Epoch 796/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5096 - val_loss: 0.5455\n",
      "Epoch 797/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5041 - val_loss: 0.6092\n",
      "Epoch 798/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5158 - val_loss: 0.5408\n",
      "Epoch 799/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5071 - val_loss: 0.5641\n",
      "Epoch 800/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5034 - val_loss: 0.6288\n",
      "Epoch 801/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5044 - val_loss: 0.5659\n",
      "Epoch 802/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5060 - val_loss: 0.5487\n",
      "Epoch 803/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5036 - val_loss: 0.6746\n",
      "Epoch 804/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5114 - val_loss: 0.5761\n",
      "Epoch 805/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5068 - val_loss: 0.5357\n",
      "Epoch 806/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5090 - val_loss: 0.5352\n",
      "Epoch 807/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5033 - val_loss: 0.6457\n",
      "Epoch 808/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5067 - val_loss: 0.6388\n",
      "Epoch 809/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5003 - val_loss: 0.5417\n",
      "Epoch 810/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5058 - val_loss: 0.5706\n",
      "Epoch 811/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5088 - val_loss: 0.6537\n",
      "Epoch 812/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5096 - val_loss: 0.5661\n",
      "Epoch 813/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5049 - val_loss: 0.5339\n",
      "Epoch 814/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5052 - val_loss: 0.5406\n",
      "Epoch 815/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5121 - val_loss: 0.5615\n",
      "Epoch 816/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5006 - val_loss: 0.5447\n",
      "Epoch 817/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5056 - val_loss: 0.5513\n",
      "Epoch 818/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5074 - val_loss: 0.5866\n",
      "Epoch 819/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4984 - val_loss: 0.5405\n",
      "Epoch 820/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5060 - val_loss: 0.5413\n",
      "Epoch 821/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4991 - val_loss: 0.5789\n",
      "Epoch 822/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5126 - val_loss: 0.6104\n",
      "Epoch 823/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5089 - val_loss: 0.5870\n",
      "Epoch 824/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5073 - val_loss: 0.5496\n",
      "Epoch 825/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4993 - val_loss: 0.5766\n",
      "Epoch 826/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5077 - val_loss: 0.5368\n",
      "Epoch 827/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5102 - val_loss: 0.5503\n",
      "Epoch 828/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5086 - val_loss: 0.5412\n",
      "Epoch 829/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5158 - val_loss: 0.5876\n",
      "Epoch 830/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5046 - val_loss: 0.5682\n",
      "Epoch 831/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5062 - val_loss: 0.5322\n",
      "Epoch 832/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5079 - val_loss: 0.5487\n",
      "Epoch 833/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5138 - val_loss: 0.5943\n",
      "Epoch 834/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5193 - val_loss: 0.5582\n",
      "Epoch 835/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5032 - val_loss: 0.6001\n",
      "Epoch 836/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5214 - val_loss: 0.6008\n",
      "Epoch 837/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5044 - val_loss: 0.5406\n",
      "Epoch 838/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5050 - val_loss: 0.5368\n",
      "Epoch 839/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5037 - val_loss: 0.6491\n",
      "Epoch 840/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5102 - val_loss: 0.5387\n",
      "Epoch 841/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5105 - val_loss: 0.5327\n",
      "Epoch 842/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5159 - val_loss: 0.6038\n",
      "Epoch 843/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4994 - val_loss: 0.5893\n",
      "Epoch 844/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5083 - val_loss: 0.5377\n",
      "Epoch 845/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5039 - val_loss: 0.5400\n",
      "Epoch 846/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5098 - val_loss: 0.5731\n",
      "Epoch 847/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5035 - val_loss: 0.5347\n",
      "Epoch 848/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5047 - val_loss: 0.5343\n",
      "Epoch 849/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5119 - val_loss: 0.5372\n",
      "Epoch 850/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5056 - val_loss: 0.6767\n",
      "Epoch 851/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5123 - val_loss: 0.5332\n",
      "Epoch 852/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4973 - val_loss: 0.5402\n",
      "Epoch 853/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5070 - val_loss: 0.5395\n",
      "Epoch 854/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5111 - val_loss: 0.6261\n",
      "Epoch 855/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5162 - val_loss: 0.5343\n",
      "Epoch 856/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4949 - val_loss: 0.5396\n",
      "Epoch 857/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5013 - val_loss: 0.5324\n",
      "Epoch 858/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5039 - val_loss: 0.6359\n",
      "Epoch 859/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5014 - val_loss: 0.5320\n",
      "Epoch 860/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5067 - val_loss: 0.5320\n",
      "Epoch 861/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4992 - val_loss: 0.5385\n",
      "Epoch 862/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5002 - val_loss: 0.5795\n",
      "Epoch 863/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5163 - val_loss: 0.5396\n",
      "Epoch 864/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5028 - val_loss: 0.5383\n",
      "Epoch 865/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5016 - val_loss: 0.5926\n",
      "Epoch 866/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5019 - val_loss: 0.5364\n",
      "Epoch 867/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5041 - val_loss: 0.5315\n",
      "Epoch 868/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5052 - val_loss: 0.5445\n",
      "Epoch 869/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5065 - val_loss: 0.6076\n",
      "Epoch 870/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5073 - val_loss: 0.6275\n",
      "Epoch 871/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5071 - val_loss: 0.5340\n",
      "Epoch 872/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5008 - val_loss: 0.5560\n",
      "Epoch 873/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5010 - val_loss: 0.5405\n",
      "Epoch 874/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4997 - val_loss: 0.5352\n",
      "Epoch 875/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4987 - val_loss: 0.5518\n",
      "Epoch 876/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5078 - val_loss: 0.5732\n",
      "Epoch 877/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5023 - val_loss: 0.7250\n",
      "Epoch 878/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5112 - val_loss: 0.5403\n",
      "Epoch 879/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4973 - val_loss: 0.5502\n",
      "Epoch 880/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5045 - val_loss: 0.5534\n",
      "Epoch 881/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4981 - val_loss: 0.5398\n",
      "Epoch 882/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5005 - val_loss: 0.5587\n",
      "Epoch 883/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5052 - val_loss: 0.5751\n",
      "Epoch 884/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4991 - val_loss: 0.6086\n",
      "Epoch 885/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5109 - val_loss: 0.5961\n",
      "Epoch 886/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5071 - val_loss: 0.5434\n",
      "Epoch 887/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5069 - val_loss: 0.5328\n",
      "Epoch 888/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4974 - val_loss: 0.5867\n",
      "Epoch 889/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5105 - val_loss: 0.5845\n",
      "Epoch 890/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5161 - val_loss: 0.5475\n",
      "Epoch 891/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5100 - val_loss: 0.5695\n",
      "Epoch 892/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5082 - val_loss: 0.6383\n",
      "Epoch 893/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5024 - val_loss: 0.5873\n",
      "Epoch 894/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5022 - val_loss: 0.6157\n",
      "Epoch 895/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5036 - val_loss: 0.5781\n",
      "Epoch 896/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5158 - val_loss: 0.5375\n",
      "Epoch 897/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4942 - val_loss: 0.5840\n",
      "Epoch 898/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5015 - val_loss: 0.5540\n",
      "Epoch 899/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5029 - val_loss: 0.5378\n",
      "Epoch 900/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4975 - val_loss: 0.5309\n",
      "Epoch 901/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5050 - val_loss: 0.5829\n",
      "Epoch 902/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5079 - val_loss: 0.5284\n",
      "Epoch 903/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4984 - val_loss: 0.5282\n",
      "Epoch 904/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5110 - val_loss: 0.5355\n",
      "Epoch 905/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5050 - val_loss: 0.5402\n",
      "Epoch 906/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5063 - val_loss: 0.5463\n",
      "Epoch 907/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5016 - val_loss: 0.5528\n",
      "Epoch 908/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4992 - val_loss: 0.5838\n",
      "Epoch 909/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5029 - val_loss: 0.5342\n",
      "Epoch 910/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4960 - val_loss: 0.5920\n",
      "Epoch 911/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5109 - val_loss: 0.5365\n",
      "Epoch 912/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4938 - val_loss: 0.6144\n",
      "Epoch 913/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5010 - val_loss: 0.5603\n",
      "Epoch 914/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5055 - val_loss: 0.6152\n",
      "Epoch 915/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5096 - val_loss: 0.5319\n",
      "Epoch 916/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4996 - val_loss: 0.5329\n",
      "Epoch 917/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5027 - val_loss: 0.5346\n",
      "Epoch 918/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5106 - val_loss: 0.5357\n",
      "Epoch 919/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5008 - val_loss: 0.5490\n",
      "Epoch 920/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5038 - val_loss: 0.5932\n",
      "Epoch 921/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5056 - val_loss: 0.5566\n",
      "Epoch 922/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5006 - val_loss: 0.5533\n",
      "Epoch 923/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5246 - val_loss: 0.5483\n",
      "Epoch 924/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4972 - val_loss: 0.5453\n",
      "Epoch 925/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5023 - val_loss: 0.6257\n",
      "Epoch 926/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5057 - val_loss: 0.5442\n",
      "Epoch 927/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4919 - val_loss: 0.5789\n",
      "Epoch 928/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5017 - val_loss: 0.5375\n",
      "Epoch 929/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5123 - val_loss: 0.5574\n",
      "Epoch 930/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5088 - val_loss: 0.5355\n",
      "Epoch 931/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4969 - val_loss: 0.5375\n",
      "Epoch 932/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4963 - val_loss: 0.5581\n",
      "Epoch 933/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5042 - val_loss: 0.5339\n",
      "Epoch 934/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4973 - val_loss: 0.5357\n",
      "Epoch 935/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5032 - val_loss: 0.5314\n",
      "Epoch 936/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5046 - val_loss: 0.6298\n",
      "Epoch 937/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5045 - val_loss: 0.6242\n",
      "Epoch 938/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5081 - val_loss: 0.5308\n",
      "Epoch 939/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5087 - val_loss: 0.5554\n",
      "Epoch 940/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5003 - val_loss: 0.5620\n",
      "Epoch 941/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4988 - val_loss: 0.5428\n",
      "Epoch 942/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5017 - val_loss: 0.6028\n",
      "Epoch 943/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5069 - val_loss: 0.6409\n",
      "Epoch 944/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4996 - val_loss: 0.5261\n",
      "Epoch 945/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5028 - val_loss: 0.5447\n",
      "Epoch 946/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5034 - val_loss: 0.5475\n",
      "Epoch 947/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4984 - val_loss: 0.5824\n",
      "Epoch 948/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5117 - val_loss: 0.5282\n",
      "Epoch 949/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5020 - val_loss: 0.5329\n",
      "Epoch 950/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4954 - val_loss: 0.5647\n",
      "Epoch 951/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5042 - val_loss: 0.5284\n",
      "Epoch 952/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5013 - val_loss: 0.5436\n",
      "Epoch 953/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5007 - val_loss: 0.5465\n",
      "Epoch 954/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5056 - val_loss: 0.5343\n",
      "Epoch 955/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4982 - val_loss: 0.5431\n",
      "Epoch 956/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4993 - val_loss: 0.5297\n",
      "Epoch 957/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5175 - val_loss: 0.5383\n",
      "Epoch 958/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4980 - val_loss: 0.5329\n",
      "Epoch 959/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4917 - val_loss: 0.8774\n",
      "Epoch 960/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5194 - val_loss: 0.6143\n",
      "Epoch 961/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5025 - val_loss: 0.5289\n",
      "Epoch 962/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5011 - val_loss: 0.5303\n",
      "Epoch 963/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4942 - val_loss: 0.6460\n",
      "Epoch 964/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5119 - val_loss: 0.5786\n",
      "Epoch 965/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4985 - val_loss: 0.5448\n",
      "Epoch 966/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5149 - val_loss: 0.7287\n",
      "Epoch 967/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5127 - val_loss: 0.5452\n",
      "Epoch 968/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4964 - val_loss: 0.5618\n",
      "Epoch 969/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5030 - val_loss: 0.6498\n",
      "Epoch 970/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5154 - val_loss: 0.5557\n",
      "Epoch 971/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4999 - val_loss: 0.5347\n",
      "Epoch 972/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4971 - val_loss: 0.5322\n",
      "Epoch 973/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4933 - val_loss: 0.5407\n",
      "Epoch 974/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4968 - val_loss: 0.5494\n",
      "Epoch 975/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4976 - val_loss: 0.5294\n",
      "Epoch 976/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5075 - val_loss: 0.6487\n",
      "Epoch 977/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4965 - val_loss: 0.5467\n",
      "Epoch 978/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5040 - val_loss: 0.5329\n",
      "Epoch 979/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5032 - val_loss: 0.5344\n",
      "Epoch 980/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4964 - val_loss: 0.5328\n",
      "Epoch 981/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5004 - val_loss: 0.5255\n",
      "Epoch 982/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4969 - val_loss: 0.5515\n",
      "Epoch 983/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4967 - val_loss: 0.6237\n",
      "Epoch 984/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5028 - val_loss: 0.5427\n",
      "Epoch 985/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4970 - val_loss: 0.6598\n",
      "Epoch 986/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5023 - val_loss: 0.5452\n",
      "Epoch 987/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4954 - val_loss: 0.6299\n",
      "Epoch 988/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5181 - val_loss: 0.5348\n",
      "Epoch 989/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4971 - val_loss: 0.6567\n",
      "Epoch 990/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5024 - val_loss: 0.5542\n",
      "Epoch 991/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4951 - val_loss: 0.5428\n",
      "Epoch 992/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4970 - val_loss: 0.5461\n",
      "Epoch 993/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4974 - val_loss: 0.5824\n",
      "Epoch 994/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5065 - val_loss: 0.5546\n",
      "Epoch 995/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4991 - val_loss: 0.5871\n",
      "Epoch 996/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4995 - val_loss: 0.5442\n",
      "Epoch 997/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4991 - val_loss: 0.6117\n",
      "Epoch 998/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5143 - val_loss: 0.5343\n",
      "Epoch 999/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5004 - val_loss: 0.5533\n",
      "Epoch 1000/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4946 - val_loss: 0.5459\n",
      "Epoch 1001/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5038 - val_loss: 0.5254\n",
      "Epoch 1002/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5019 - val_loss: 0.5296\n",
      "Epoch 1003/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4930 - val_loss: 0.5301\n",
      "Epoch 1004/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4941 - val_loss: 0.5426\n",
      "Epoch 1005/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4950 - val_loss: 0.5322\n",
      "Epoch 1006/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5018 - val_loss: 0.5280\n",
      "Epoch 1007/1300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.5051 - val_loss: 0.5371\n",
      "Epoch 1008/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4967 - val_loss: 0.5584\n",
      "Epoch 1009/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4943 - val_loss: 0.5389\n",
      "Epoch 1010/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5031 - val_loss: 0.5533\n",
      "Epoch 1011/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5106 - val_loss: 0.5432\n",
      "Epoch 1012/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4981 - val_loss: 0.6113\n",
      "Epoch 1013/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5040 - val_loss: 0.5482\n",
      "Epoch 1014/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4975 - val_loss: 0.5498\n",
      "Epoch 1015/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5088 - val_loss: 0.5391\n",
      "Epoch 1016/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4950 - val_loss: 0.5348\n",
      "Epoch 1017/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4988 - val_loss: 0.5548\n",
      "Epoch 1018/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4891 - val_loss: 0.5307\n",
      "Epoch 1019/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4952 - val_loss: 0.5501\n",
      "Epoch 1020/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4977 - val_loss: 0.5259\n",
      "Epoch 1021/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5060 - val_loss: 0.5429\n",
      "Epoch 1022/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5020 - val_loss: 0.6041\n",
      "Epoch 1023/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5023 - val_loss: 0.6222\n",
      "Epoch 1024/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4973 - val_loss: 0.5372\n",
      "Epoch 1025/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4999 - val_loss: 0.5427\n",
      "Epoch 1026/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5021 - val_loss: 0.6020\n",
      "Epoch 1027/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5046 - val_loss: 0.5502\n",
      "Epoch 1028/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4990 - val_loss: 0.5475\n",
      "Epoch 1029/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4903 - val_loss: 0.5308\n",
      "Epoch 1030/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4961 - val_loss: 0.5469\n",
      "Epoch 1031/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4908 - val_loss: 0.5281\n",
      "Epoch 1032/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4950 - val_loss: 0.5373\n",
      "Epoch 1033/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4985 - val_loss: 0.5356\n",
      "Epoch 1034/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4949 - val_loss: 0.5380\n",
      "Epoch 1035/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4948 - val_loss: 0.5632\n",
      "Epoch 1036/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5005 - val_loss: 0.5427\n",
      "Epoch 1037/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5011 - val_loss: 0.5718\n",
      "Epoch 1038/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4977 - val_loss: 0.5307\n",
      "Epoch 1039/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4956 - val_loss: 0.5498\n",
      "Epoch 1040/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5025 - val_loss: 0.5291\n",
      "Epoch 1041/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4894 - val_loss: 0.5268\n",
      "Epoch 1042/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4989 - val_loss: 0.5394\n",
      "Epoch 1043/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4922 - val_loss: 0.7520\n",
      "Epoch 1044/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4981 - val_loss: 0.5338\n",
      "Epoch 1045/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4987 - val_loss: 0.6024\n",
      "Epoch 1046/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5073 - val_loss: 0.5249\n",
      "Epoch 1047/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4943 - val_loss: 0.5328\n",
      "Epoch 1048/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5012 - val_loss: 0.5751\n",
      "Epoch 1049/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4932 - val_loss: 0.5613\n",
      "Epoch 1050/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5055 - val_loss: 0.5477\n",
      "Epoch 1051/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4911 - val_loss: 0.5212\n",
      "Epoch 1052/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4988 - val_loss: 0.5642\n",
      "Epoch 1053/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5009 - val_loss: 0.5283\n",
      "Epoch 1054/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5052 - val_loss: 0.5933\n",
      "Epoch 1055/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4978 - val_loss: 0.5307\n",
      "Epoch 1056/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5098 - val_loss: 0.5552\n",
      "Epoch 1057/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4932 - val_loss: 0.6130\n",
      "Epoch 1058/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4949 - val_loss: 0.5397\n",
      "Epoch 1059/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4949 - val_loss: 0.5611\n",
      "Epoch 1060/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5016 - val_loss: 0.5371\n",
      "Epoch 1061/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4827 - val_loss: 0.5483\n",
      "Epoch 1062/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4921 - val_loss: 0.6367\n",
      "Epoch 1063/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4914 - val_loss: 0.5296\n",
      "Epoch 1064/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4999 - val_loss: 0.5482\n",
      "Epoch 1065/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4959 - val_loss: 0.5387\n",
      "Epoch 1066/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4895 - val_loss: 0.5281\n",
      "Epoch 1067/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4965 - val_loss: 0.5736\n",
      "Epoch 1068/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4896 - val_loss: 0.5265\n",
      "Epoch 1069/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4964 - val_loss: 0.5380\n",
      "Epoch 1070/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4993 - val_loss: 0.5320\n",
      "Epoch 1071/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4944 - val_loss: 0.5995\n",
      "Epoch 1072/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5178 - val_loss: 0.5454\n",
      "Epoch 1073/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4921 - val_loss: 0.5752\n",
      "Epoch 1074/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4965 - val_loss: 0.5463\n",
      "Epoch 1075/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4926 - val_loss: 0.5940\n",
      "Epoch 1076/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4908 - val_loss: 0.5314\n",
      "Epoch 1077/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5119 - val_loss: 0.5394\n",
      "Epoch 1078/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4994 - val_loss: 0.5566\n",
      "Epoch 1079/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4970 - val_loss: 0.5266\n",
      "Epoch 1080/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4994 - val_loss: 0.6172\n",
      "Epoch 1081/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4980 - val_loss: 0.6143\n",
      "Epoch 1082/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5015 - val_loss: 0.5250\n",
      "Epoch 1083/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4907 - val_loss: 0.5698\n",
      "Epoch 1084/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5129 - val_loss: 0.5293\n",
      "Epoch 1085/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5028 - val_loss: 0.5271\n",
      "Epoch 1086/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4915 - val_loss: 0.5514\n",
      "Epoch 1087/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4993 - val_loss: 0.5440\n",
      "Epoch 1088/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4899 - val_loss: 0.5365\n",
      "Epoch 1089/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4913 - val_loss: 0.5524\n",
      "Epoch 1090/1300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.4944 - val_loss: 0.5546\n",
      "Epoch 1091/1300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.4946 - val_loss: 0.5546\n",
      "Epoch 1092/1300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.4953 - val_loss: 0.5522\n",
      "Epoch 1093/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5060 - val_loss: 0.5405\n",
      "Epoch 1094/1300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.4927 - val_loss: 0.5415\n",
      "Epoch 1095/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4891 - val_loss: 0.5965\n",
      "Epoch 1096/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5230 - val_loss: 0.5660\n",
      "Epoch 1097/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4979 - val_loss: 0.5276\n",
      "Epoch 1098/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4895 - val_loss: 0.7396\n",
      "Epoch 1099/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5000 - val_loss: 0.5324\n",
      "Epoch 1100/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4939 - val_loss: 0.5455\n",
      "Epoch 1101/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4931 - val_loss: 0.5654\n",
      "Epoch 1102/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4898 - val_loss: 0.5670\n",
      "Epoch 1103/1300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.4849 - val_loss: 0.5557\n",
      "Epoch 1104/1300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.4900 - val_loss: 0.5219\n",
      "Epoch 1105/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5102 - val_loss: 0.5378\n",
      "Epoch 1106/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4913 - val_loss: 0.5631\n",
      "Epoch 1107/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4882 - val_loss: 0.5217\n",
      "Epoch 1108/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4910 - val_loss: 0.5391\n",
      "Epoch 1109/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4900 - val_loss: 0.5207\n",
      "Epoch 1110/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4901 - val_loss: 0.5579\n",
      "Epoch 1111/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5034 - val_loss: 0.5415\n",
      "Epoch 1112/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5008 - val_loss: 0.6884\n",
      "Epoch 1113/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5049 - val_loss: 0.5191\n",
      "Epoch 1114/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4951 - val_loss: 0.5235\n",
      "Epoch 1115/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4989 - val_loss: 0.5254\n",
      "Epoch 1116/1300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.4914 - val_loss: 0.5267\n",
      "Epoch 1117/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4999 - val_loss: 0.5226\n",
      "Epoch 1118/1300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.4978 - val_loss: 0.6070\n",
      "Epoch 1119/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4967 - val_loss: 0.5474\n",
      "Epoch 1120/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4942 - val_loss: 0.6667\n",
      "Epoch 1121/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5095 - val_loss: 0.5291\n",
      "Epoch 1122/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5009 - val_loss: 0.5763\n",
      "Epoch 1123/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4936 - val_loss: 0.5280\n",
      "Epoch 1124/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4906 - val_loss: 0.5243\n",
      "Epoch 1125/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4893 - val_loss: 0.7074\n",
      "Epoch 1126/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4986 - val_loss: 0.6029\n",
      "Epoch 1127/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4952 - val_loss: 0.5438\n",
      "Epoch 1128/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4989 - val_loss: 0.5656\n",
      "Epoch 1129/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4997 - val_loss: 0.5622\n",
      "Epoch 1130/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4911 - val_loss: 0.5449\n",
      "Epoch 1131/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4878 - val_loss: 0.5322\n",
      "Epoch 1132/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4903 - val_loss: 0.5735\n",
      "Epoch 1133/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4910 - val_loss: 0.5313\n",
      "Epoch 1134/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4889 - val_loss: 0.5492\n",
      "Epoch 1135/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4935 - val_loss: 0.5286\n",
      "Epoch 1136/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4899 - val_loss: 0.5497\n",
      "Epoch 1137/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4943 - val_loss: 0.5257\n",
      "Epoch 1138/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5048 - val_loss: 0.5646\n",
      "Epoch 1139/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4903 - val_loss: 0.5323\n",
      "Epoch 1140/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4897 - val_loss: 0.5282\n",
      "Epoch 1141/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4998 - val_loss: 0.5425\n",
      "Epoch 1142/1300\n",
      "233/233 [==============================] - 2s 9ms/step - loss: 0.5019 - val_loss: 0.5345\n",
      "Epoch 1143/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4869 - val_loss: 0.5249\n",
      "Epoch 1144/1300\n",
      "233/233 [==============================] - 2s 7ms/step - loss: 0.4915 - val_loss: 0.5233\n",
      "Epoch 1145/1300\n",
      "233/233 [==============================] - 2s 8ms/step - loss: 0.4959 - val_loss: 0.5354\n",
      "Epoch 1146/1300\n",
      "233/233 [==============================] - 2s 6ms/step - loss: 0.5068 - val_loss: 0.5211\n",
      "Epoch 1147/1300\n",
      "233/233 [==============================] - 2s 8ms/step - loss: 0.4926 - val_loss: 0.5246\n",
      "Epoch 1148/1300\n",
      "233/233 [==============================] - 2s 7ms/step - loss: 0.5017 - val_loss: 0.5525\n",
      "Epoch 1149/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5043 - val_loss: 0.5432\n",
      "Epoch 1150/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4871 - val_loss: 0.5472\n",
      "Epoch 1151/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4919 - val_loss: 0.5865\n",
      "Epoch 1152/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4951 - val_loss: 0.5419\n",
      "Epoch 1153/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4943 - val_loss: 0.5287\n",
      "Epoch 1154/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4887 - val_loss: 0.5452\n",
      "Epoch 1155/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4846 - val_loss: 0.6129\n",
      "Epoch 1156/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4987 - val_loss: 0.5589\n",
      "Epoch 1157/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4920 - val_loss: 0.5379\n",
      "Epoch 1158/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4918 - val_loss: 0.7000\n",
      "Epoch 1159/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5197 - val_loss: 0.5211\n",
      "Epoch 1160/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4864 - val_loss: 0.5570\n",
      "Epoch 1161/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4945 - val_loss: 0.6227\n",
      "Epoch 1162/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5061 - val_loss: 0.5520\n",
      "Epoch 1163/1300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.4923 - val_loss: 0.5241\n",
      "Epoch 1164/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4934 - val_loss: 0.5412\n",
      "Epoch 1165/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4934 - val_loss: 0.5514\n",
      "Epoch 1166/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4842 - val_loss: 0.6308\n",
      "Epoch 1167/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4936 - val_loss: 0.5250\n",
      "Epoch 1168/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4925 - val_loss: 0.5219\n",
      "Epoch 1169/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4896 - val_loss: 0.5671\n",
      "Epoch 1170/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5059 - val_loss: 0.5479\n",
      "Epoch 1171/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5096 - val_loss: 0.5425\n",
      "Epoch 1172/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4917 - val_loss: 0.5299\n",
      "Epoch 1173/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4946 - val_loss: 0.5622\n",
      "Epoch 1174/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5024 - val_loss: 0.5455\n",
      "Epoch 1175/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4928 - val_loss: 0.5299\n",
      "Epoch 1176/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4867 - val_loss: 0.5530\n",
      "Epoch 1177/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4973 - val_loss: 0.5270\n",
      "Epoch 1178/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4948 - val_loss: 0.6624\n",
      "Epoch 1179/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5051 - val_loss: 0.5467\n",
      "Epoch 1180/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4894 - val_loss: 0.5302\n",
      "Epoch 1181/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4839 - val_loss: 0.6103\n",
      "Epoch 1182/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5012 - val_loss: 0.5281\n",
      "Epoch 1183/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4956 - val_loss: 0.6328\n",
      "Epoch 1184/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4947 - val_loss: 0.5287\n",
      "Epoch 1185/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4892 - val_loss: 0.5306\n",
      "Epoch 1186/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4921 - val_loss: 0.5682\n",
      "Epoch 1187/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5010 - val_loss: 0.5722\n",
      "Epoch 1188/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4998 - val_loss: 0.5268\n",
      "Epoch 1189/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5028 - val_loss: 0.5802\n",
      "Epoch 1190/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4915 - val_loss: 0.5542\n",
      "Epoch 1191/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4888 - val_loss: 0.6038\n",
      "Epoch 1192/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4973 - val_loss: 0.5214\n",
      "Epoch 1193/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5021 - val_loss: 0.5457\n",
      "Epoch 1194/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5010 - val_loss: 0.5205\n",
      "Epoch 1195/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4908 - val_loss: 0.5200\n",
      "Epoch 1196/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4864 - val_loss: 0.5295\n",
      "Epoch 1197/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4957 - val_loss: 0.6900\n",
      "Epoch 1198/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4921 - val_loss: 0.5211\n",
      "Epoch 1199/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4873 - val_loss: 0.5721\n",
      "Epoch 1200/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4867 - val_loss: 0.5226\n",
      "Epoch 1201/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5000 - val_loss: 0.5314\n",
      "Epoch 1202/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4885 - val_loss: 0.5323\n",
      "Epoch 1203/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4898 - val_loss: 0.5210\n",
      "Epoch 1204/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4964 - val_loss: 0.5945\n",
      "Epoch 1205/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4972 - val_loss: 0.5273\n",
      "Epoch 1206/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4862 - val_loss: 0.5400\n",
      "Epoch 1207/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5035 - val_loss: 0.5541\n",
      "Epoch 1208/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4927 - val_loss: 0.5561\n",
      "Epoch 1209/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5000 - val_loss: 0.5326\n",
      "Epoch 1210/1300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.4931 - val_loss: 0.5950\n",
      "Epoch 1211/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4936 - val_loss: 0.5594\n",
      "Epoch 1212/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5122 - val_loss: 0.5470\n",
      "Epoch 1213/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4896 - val_loss: 0.5273\n",
      "Epoch 1214/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4889 - val_loss: 0.5296\n",
      "Epoch 1215/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4928 - val_loss: 0.6559\n",
      "Epoch 1216/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4965 - val_loss: 0.5478\n",
      "Epoch 1217/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4918 - val_loss: 0.5252\n",
      "Epoch 1218/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4952 - val_loss: 0.5874\n",
      "Epoch 1219/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4950 - val_loss: 0.5252\n",
      "Epoch 1220/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4855 - val_loss: 0.6798\n",
      "Epoch 1221/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4994 - val_loss: 0.5605\n",
      "Epoch 1222/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4924 - val_loss: 0.5269\n",
      "Epoch 1223/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4904 - val_loss: 0.5689\n",
      "Epoch 1224/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4862 - val_loss: 0.8462\n",
      "Epoch 1225/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4974 - val_loss: 0.5652\n",
      "Epoch 1226/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4958 - val_loss: 0.6034\n",
      "Epoch 1227/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4893 - val_loss: 0.5418\n",
      "Epoch 1228/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 0.5936\n",
      "Epoch 1229/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4977 - val_loss: 0.5623\n",
      "Epoch 1230/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4813 - val_loss: 0.5206\n",
      "Epoch 1231/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4989 - val_loss: 0.6089\n",
      "Epoch 1232/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4928 - val_loss: 0.5771\n",
      "Epoch 1233/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4983 - val_loss: 0.5242\n",
      "Epoch 1234/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4955 - val_loss: 0.5266\n",
      "Epoch 1235/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4896 - val_loss: 0.5237\n",
      "Epoch 1236/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4862 - val_loss: 0.5245\n",
      "Epoch 1237/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4898 - val_loss: 0.5373\n",
      "Epoch 1238/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4904 - val_loss: 0.5259\n",
      "Epoch 1239/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4945 - val_loss: 0.5864\n",
      "Epoch 1240/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4948 - val_loss: 0.5260\n",
      "Epoch 1241/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4838 - val_loss: 0.5680\n",
      "Epoch 1242/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4891 - val_loss: 0.5244\n",
      "Epoch 1243/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5012 - val_loss: 0.5375\n",
      "Epoch 1244/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4855 - val_loss: 0.5226\n",
      "Epoch 1245/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4869 - val_loss: 0.5235\n",
      "Epoch 1246/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4909 - val_loss: 0.6748\n",
      "Epoch 1247/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4994 - val_loss: 0.5224\n",
      "Epoch 1248/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4924 - val_loss: 0.5523\n",
      "Epoch 1249/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4945 - val_loss: 0.5221\n",
      "Epoch 1250/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4938 - val_loss: 0.5217\n",
      "Epoch 1251/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4896 - val_loss: 0.5636\n",
      "Epoch 1252/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4955 - val_loss: 0.5840\n",
      "Epoch 1253/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4942 - val_loss: 0.5263\n",
      "Epoch 1254/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4837 - val_loss: 0.5553\n",
      "Epoch 1255/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4999 - val_loss: 0.6273\n",
      "Epoch 1256/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4856 - val_loss: 0.5381\n",
      "Epoch 1257/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4818 - val_loss: 0.5212\n",
      "Epoch 1258/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4928 - val_loss: 0.5892\n",
      "Epoch 1259/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4976 - val_loss: 0.5754\n",
      "Epoch 1260/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4939 - val_loss: 0.5527\n",
      "Epoch 1261/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4874 - val_loss: 0.5562\n",
      "Epoch 1262/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4874 - val_loss: 0.5579\n",
      "Epoch 1263/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4865 - val_loss: 0.5660\n",
      "Epoch 1264/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4925 - val_loss: 0.5268\n",
      "Epoch 1265/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4910 - val_loss: 0.5496\n",
      "Epoch 1266/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4945 - val_loss: 0.5365\n",
      "Epoch 1267/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4913 - val_loss: 0.5433\n",
      "Epoch 1268/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4917 - val_loss: 0.5304\n",
      "Epoch 1269/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4913 - val_loss: 0.5257\n",
      "Epoch 1270/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4858 - val_loss: 0.5259\n",
      "Epoch 1271/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4887 - val_loss: 0.5416\n",
      "Epoch 1272/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4882 - val_loss: 0.6049\n",
      "Epoch 1273/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4918 - val_loss: 0.5697\n",
      "Epoch 1274/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.5014 - val_loss: 0.5250\n",
      "Epoch 1275/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4932 - val_loss: 0.5249\n",
      "Epoch 1276/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4955 - val_loss: 0.5206\n",
      "Epoch 1277/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4945 - val_loss: 0.5268\n",
      "Epoch 1278/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4944 - val_loss: 0.5233\n",
      "Epoch 1279/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5019 - val_loss: 0.5645\n",
      "Epoch 1280/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4883 - val_loss: 0.5988\n",
      "Epoch 1281/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4962 - val_loss: 0.5225\n",
      "Epoch 1282/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4877 - val_loss: 0.5782\n",
      "Epoch 1283/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4849 - val_loss: 0.5286\n",
      "Epoch 1284/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4912 - val_loss: 0.5419\n",
      "Epoch 1285/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4939 - val_loss: 0.5374\n",
      "Epoch 1286/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4950 - val_loss: 0.5293\n",
      "Epoch 1287/1300\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.4992 - val_loss: 0.5432\n",
      "Epoch 1288/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4857 - val_loss: 0.5265\n",
      "Epoch 1289/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4941 - val_loss: 0.6728\n",
      "Epoch 1290/1300\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.4963 - val_loss: 0.5803\n",
      "Epoch 1291/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.5006 - val_loss: 0.5480\n",
      "Epoch 1292/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4900 - val_loss: 0.5313\n",
      "Epoch 1293/1300\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 0.4872 - val_loss: 0.5474\n",
      "Epoch 1294/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4982 - val_loss: 0.5211\n",
      "Epoch 1295/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4893 - val_loss: 0.5235\n",
      "Epoch 1296/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4884 - val_loss: 0.6142\n",
      "Epoch 1297/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4940 - val_loss: 0.5834\n",
      "Epoch 1298/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4892 - val_loss: 0.6558\n",
      "Epoch 1299/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4893 - val_loss: 0.5337\n",
      "Epoch 1300/1300\n",
      "233/233 [==============================] - 1s 4ms/step - loss: 0.4937 - val_loss: 0.5232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f1416031c90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=128,epochs=1300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hEJQctXRhqPc",
    "outputId": "2eed4da4-6b80-4e97-8d14-d466304cc4f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 19)                190       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 19)                380       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 19)                380       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 19)                380       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 19)                380       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1730 (6.76 KB)\n",
      "Trainable params: 1730 (6.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "cyHcNE8vl_6U"
   },
   "outputs": [],
   "source": [
    "loss_df=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "c5ImdpWRmCcx",
    "outputId": "e2b1c83b-7d67-4264-bac5-507487a10cfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plJ8x-w0mEIw",
    "outputId": "119d9db6-6d4c-4cde-ff0f-3811085d7e09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/233 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nKU_0sfWmbHP",
    "outputId": "db8865d6-3b6f-427b-a248-cee0f084cec6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6151750576697186"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,tahmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSaeYvtKmds9",
    "outputId": "1066fa72-516b-428e-bab5-cc6c7c07e723"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7233000039693898"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,tahmin)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGbHGjnTmgO9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "15a640bae0044561b5b568deab656e24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "1d24289968ef489a846bb98057925ac2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fd6c38a079e4a7ea056654f05ccc956": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52207eaea9384405be8cbe0279b525ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bfa6b63783f4e6c8fdfd3591a80fa33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "61c1a3bcd6b84fdf8f38a02fd8d830d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a4da9af37304feb9164731641f5df6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d24289968ef489a846bb98057925ac2",
      "max": 81,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bf104749b1304c5a9fd12bf389ffba5f",
      "value": 81
     }
    },
    "8d923bc135a64c1e81874d10b8aceafe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4fd6c38a079e4a7ea056654f05ccc956",
      "placeholder": "​",
      "style": "IPY_MODEL_52207eaea9384405be8cbe0279b525ac",
      "value": "Processing: 100%"
     }
    },
    "b350b484302e4becba6eb41fd9826be8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8d923bc135a64c1e81874d10b8aceafe",
       "IPY_MODEL_6a4da9af37304feb9164731641f5df6f",
       "IPY_MODEL_cc8f468eda794a8ca0302617f958113d"
      ],
      "layout": "IPY_MODEL_15a640bae0044561b5b568deab656e24"
     }
    },
    "bf104749b1304c5a9fd12bf389ffba5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cc8f468eda794a8ca0302617f958113d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61c1a3bcd6b84fdf8f38a02fd8d830d2",
      "placeholder": "​",
      "style": "IPY_MODEL_5bfa6b63783f4e6c8fdfd3591a80fa33",
      "value": " 81/81 [06:13&lt;00:00,  1.62s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
